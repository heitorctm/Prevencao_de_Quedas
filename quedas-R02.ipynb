{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo vortex.png\" style=\"width: 40px; height: auto;\"><font color=purple size=12px>PREVENÇÃO DE QUEDAS</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>1 - Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>2 - Pré processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudando os nomes para preservar a identidade dos voluntários\n",
    "dados = pd.read_excel('dados_quedas.xlsx')\n",
    "nomes_unicos = dados['VOLUNTARIO'].unique()\n",
    "mapeamento_nomes = {nome: f'voluntario{i+1}' for i, nome in enumerate(nomes_unicos)}\n",
    "dados['VOLUNTARIO'] = dados['VOLUNTARIO'].map(mapeamento_nomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pichau\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# transformando as posicoes em one hot\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "POSICAO_encoded = encoder.fit_transform(dados[['POSICAO']])\n",
    "POSICAO_df = pd.DataFrame(POSICAO_encoded, columns=encoder.get_feature_names_out(['POSICAO'])) # meu Y\n",
    "\n",
    "dados = pd.concat([dados, POSICAO_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção dos ruídos pela formula dos quartis\n",
    "def remove_outliers(db):\n",
    "    for col in ['A', 'B', 'C', 'D']:\n",
    "        \n",
    "        Q1 = db[col].quantile(0.25)\n",
    "        Q3 = db[col].quantile(0.75)\n",
    "        \n",
    "        IIQ = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5 * IIQ\n",
    "        upper_limit = Q3 + 1.5 * IIQ\n",
    "        selecao = (db[col] >= lower_limit) & (db[col] <= upper_limit)\n",
    "        \n",
    "        db = db[selecao]\n",
    "    return db\n",
    "\n",
    "# salvando dados ja analisados\n",
    "dados = dados.groupby(['VOLUNTARIO', 'POSICAO']).apply(remove_outliers)\n",
    "\n",
    "# DEPOIS QUE EXECUTAR ESSA CELULA, COMENTE A LINHA ABAIXO, NAO PRECISAS SALVAR NOVAMENTE!!\n",
    "#dados.to_csv('dados_analisado.csv', sep = ';', index = False ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo duas pessoas dos dados para serem usados mais tarde na validação\n",
    "voluntarios_validacao = ['voluntario3', 'voluntario14']\n",
    "auxiliar = dados['VOLUNTARIO'].isin(voluntarios_validacao)\n",
    "dados_validacao = dados[auxiliar]\n",
    "auxiliar = ~dados['VOLUNTARIO'].isin(voluntarios_validacao)\n",
    "dados_treino = dados[auxiliar]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>3 - Definições e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilizando placa de video\n"
     ]
    }
   ],
   "source": [
    "# verificando se a placa de vídeo está sendo utilizada\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(\"utilizando placa de video\")\n",
    "else:\n",
    "    print(\"rodando na cpu, reinicie o processo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar o point para salvar os pesos de 2 em 2 epocas de cada fold\n",
    "def create_checkpoint(fold_num):\n",
    "    filepath = f'modelos salvos/melhor_modelo_fold{fold_num:02d}_epoch{{epoch:02d}}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        period=2)\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "# callback de redução de taxa de aprendizado, reduz em 50% se nai mudar em 3 epocas\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros\n",
    "camada_1 = 1024\n",
    "camada_2 = 512\n",
    "lr = 0.0005\n",
    "folds = 5\n",
    "batch = 5000 #X_treino.shape[0]\n",
    "funcao_perda ='categorical_crossentropy' #'mean_absolute_error' #'mean_squared_error' 'categorical_crossentropy'\n",
    "otimizador = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "epocas = 50\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=12345)\n",
    "\n",
    "# definindo arquitetura da rede\n",
    "def MLP():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(camada_1, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(camada_2, activation='relu'))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=funcao_perda, optimizer=otimizador, metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados_treino[['A', 'B', 'C', 'D']]\n",
    "Y = dados_treino[POSICAO_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 7ms/step - loss: 0.7290 - accuracy: 0.8380 - val_loss: 0.3230 - val_accuracy: 0.9001 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.2619 - accuracy: 0.9094\n",
      "Epoch 2: saving model to modelos salvos\\melhor_modelo_fold01_epoch02.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.9100 - val_loss: 0.2314 - val_accuracy: 0.9209 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9223 - val_loss: 0.2137 - val_accuracy: 0.9214 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.2037 - accuracy: 0.9277\n",
      "Epoch 4: saving model to modelos salvos\\melhor_modelo_fold01_epoch04.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9275 - val_loss: 0.2003 - val_accuracy: 0.9250 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9314 - val_loss: 0.1848 - val_accuracy: 0.9341 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1777 - accuracy: 0.9354\n",
      "Epoch 6: saving model to modelos salvos\\melhor_modelo_fold01_epoch06.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9354 - val_loss: 0.1847 - val_accuracy: 0.9290 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9382 - val_loss: 0.1672 - val_accuracy: 0.9402 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "33/50 [==================>...........] - ETA: 0s - loss: 0.1627 - accuracy: 0.9412\n",
      "Epoch 8: saving model to modelos salvos\\melhor_modelo_fold01_epoch08.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9418 - val_loss: 0.1595 - val_accuracy: 0.9411 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9416 - val_loss: 0.1551 - val_accuracy: 0.9385 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1503 - accuracy: 0.9434\n",
      "Epoch 10: saving model to modelos salvos\\melhor_modelo_fold01_epoch10.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9429 - val_loss: 0.1536 - val_accuracy: 0.9426 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9454 - val_loss: 0.1462 - val_accuracy: 0.9442 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1403 - accuracy: 0.9470\n",
      "Epoch 12: saving model to modelos salvos\\melhor_modelo_fold01_epoch12.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.9471 - val_loss: 0.1406 - val_accuracy: 0.9466 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9482 - val_loss: 0.1383 - val_accuracy: 0.9495 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9499\n",
      "Epoch 14: saving model to modelos salvos\\melhor_modelo_fold01_epoch14.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9499 - val_loss: 0.1349 - val_accuracy: 0.9495 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9492 - val_loss: 0.1316 - val_accuracy: 0.9489 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.1251 - accuracy: 0.9516\n",
      "Epoch 16: saving model to modelos salvos\\melhor_modelo_fold01_epoch16.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9516 - val_loss: 0.1432 - val_accuracy: 0.9461 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9518 - val_loss: 0.1227 - val_accuracy: 0.9511 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.1186 - accuracy: 0.9537\n",
      "Epoch 18: saving model to modelos salvos\\melhor_modelo_fold01_epoch18.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9536 - val_loss: 0.1202 - val_accuracy: 0.9530 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9558 - val_loss: 0.1145 - val_accuracy: 0.9550 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.1122 - accuracy: 0.9565\n",
      "Epoch 20: saving model to modelos salvos\\melhor_modelo_fold01_epoch20.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9570 - val_loss: 0.1121 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9595 - val_loss: 0.1109 - val_accuracy: 0.9559 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1080 - accuracy: 0.9583\n",
      "Epoch 22: saving model to modelos salvos\\melhor_modelo_fold01_epoch22.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9584 - val_loss: 0.1191 - val_accuracy: 0.9504 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.1193 - val_accuracy: 0.9555 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1038 - accuracy: 0.9614\n",
      "Epoch 24: saving model to modelos salvos\\melhor_modelo_fold01_epoch24.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9620 - val_loss: 0.1012 - val_accuracy: 0.9642 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9641 - val_loss: 0.0988 - val_accuracy: 0.9674 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0965 - accuracy: 0.9651\n",
      "Epoch 26: saving model to modelos salvos\\melhor_modelo_fold01_epoch26.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9655 - val_loss: 0.0974 - val_accuracy: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9664 - val_loss: 0.0954 - val_accuracy: 0.9672 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0913 - accuracy: 0.9678\n",
      "Epoch 28: saving model to modelos salvos\\melhor_modelo_fold01_epoch28.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9679 - val_loss: 0.0944 - val_accuracy: 0.9655 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9685 - val_loss: 0.0895 - val_accuracy: 0.9668 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0861 - accuracy: 0.9711\n",
      "Epoch 30: saving model to modelos salvos\\melhor_modelo_fold01_epoch30.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9714 - val_loss: 0.0917 - val_accuracy: 0.9678 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9714 - val_loss: 0.0904 - val_accuracy: 0.9639 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0833 - accuracy: 0.9721\n",
      "Epoch 32: saving model to modelos salvos\\melhor_modelo_fold01_epoch32.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9726 - val_loss: 0.0834 - val_accuracy: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9734 - val_loss: 0.0855 - val_accuracy: 0.9705 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0796 - accuracy: 0.9735\n",
      "Epoch 34: saving model to modelos salvos\\melhor_modelo_fold01_epoch34.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.0814 - val_accuracy: 0.9733 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.0824 - val_accuracy: 0.9708 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0754 - accuracy: 0.9756\n",
      "Epoch 36: saving model to modelos salvos\\melhor_modelo_fold01_epoch36.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9755 - val_loss: 0.0776 - val_accuracy: 0.9752 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 0.0772 - val_accuracy: 0.9742 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0728 - accuracy: 0.9767\n",
      "Epoch 38: saving model to modelos salvos\\melhor_modelo_fold01_epoch38.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.0767 - val_accuracy: 0.9735 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9763 - val_loss: 0.0758 - val_accuracy: 0.9747 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0697 - accuracy: 0.9783\n",
      "Epoch 40: saving model to modelos salvos\\melhor_modelo_fold01_epoch40.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9780 - val_loss: 0.0784 - val_accuracy: 0.9710 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.0749 - val_accuracy: 0.9738 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0694 - accuracy: 0.9776\n",
      "Epoch 42: saving model to modelos salvos\\melhor_modelo_fold01_epoch42.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9776 - val_loss: 0.0715 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9787 - val_loss: 0.0677 - val_accuracy: 0.9786 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0649 - accuracy: 0.9799\n",
      "Epoch 44: saving model to modelos salvos\\melhor_modelo_fold01_epoch44.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.0684 - val_accuracy: 0.9768 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.0641 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "40/50 [=======================>......] - ETA: 0s - loss: 0.0611 - accuracy: 0.9819\n",
      "Epoch 46: saving model to modelos salvos\\melhor_modelo_fold01_epoch46.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0646 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0604 - accuracy: 0.9820\n",
      "Epoch 48: saving model to modelos salvos\\melhor_modelo_fold01_epoch48.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9823 - val_loss: 0.0647 - val_accuracy: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.0627 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0584 - accuracy: 0.9827\n",
      "Epoch 50: saving model to modelos salvos\\melhor_modelo_fold01_epoch50.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9828 - val_loss: 0.0605 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "1921/1921 [==============================] - 3s 2ms/step - loss: 0.0605 - accuracy: 0.9815\n",
      "metricas da fold: [0.06053749844431877, 0.9815462827682495]\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 9ms/step - loss: 0.8295 - accuracy: 0.7886 - val_loss: 0.2427 - val_accuracy: 0.9103 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.2183 - accuracy: 0.9213\n",
      "Epoch 2: saving model to modelos salvos\\melhor_modelo_fold02_epoch02.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9225 - val_loss: 0.1985 - val_accuracy: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9324 - val_loss: 0.1787 - val_accuracy: 0.9351 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1753 - accuracy: 0.9367\n",
      "Epoch 4: saving model to modelos salvos\\melhor_modelo_fold02_epoch04.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9373 - val_loss: 0.1684 - val_accuracy: 0.9406 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9401 - val_loss: 0.1595 - val_accuracy: 0.9392 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9432\n",
      "Epoch 6: saving model to modelos salvos\\melhor_modelo_fold02_epoch06.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9431 - val_loss: 0.1512 - val_accuracy: 0.9449 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9450 - val_loss: 0.1441 - val_accuracy: 0.9454 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1423 - accuracy: 0.9468\n",
      "Epoch 8: saving model to modelos salvos\\melhor_modelo_fold02_epoch08.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9466 - val_loss: 0.1395 - val_accuracy: 0.9467 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9477 - val_loss: 0.1335 - val_accuracy: 0.9498 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1321 - accuracy: 0.9491\n",
      "Epoch 10: saving model to modelos salvos\\melhor_modelo_fold02_epoch10.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9488 - val_loss: 0.1298 - val_accuracy: 0.9499 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9494 - val_loss: 0.1265 - val_accuracy: 0.9512 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1243 - accuracy: 0.9513\n",
      "Epoch 12: saving model to modelos salvos\\melhor_modelo_fold02_epoch12.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9512 - val_loss: 0.1212 - val_accuracy: 0.9526 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9523 - val_loss: 0.1183 - val_accuracy: 0.9528 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9539\n",
      "Epoch 14: saving model to modelos salvos\\melhor_modelo_fold02_epoch14.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.1162 - val_accuracy: 0.9542 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9555 - val_loss: 0.1106 - val_accuracy: 0.9572 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.1128 - accuracy: 0.9563\n",
      "Epoch 16: saving model to modelos salvos\\melhor_modelo_fold02_epoch16.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9563 - val_loss: 0.1111 - val_accuracy: 0.9544 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9578 - val_loss: 0.1089 - val_accuracy: 0.9588 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1071 - accuracy: 0.9587\n",
      "Epoch 18: saving model to modelos salvos\\melhor_modelo_fold02_epoch18.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9594 - val_loss: 0.1033 - val_accuracy: 0.9615 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9608 - val_loss: 0.1015 - val_accuracy: 0.9632 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1012 - accuracy: 0.9621\n",
      "Epoch 20: saving model to modelos salvos\\melhor_modelo_fold02_epoch20.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9621 - val_loss: 0.1001 - val_accuracy: 0.9611 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9621 - val_loss: 0.0953 - val_accuracy: 0.9655 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0953 - accuracy: 0.9650\n",
      "Epoch 22: saving model to modelos salvos\\melhor_modelo_fold02_epoch22.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9651 - val_loss: 0.0952 - val_accuracy: 0.9636 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9655 - val_loss: 0.0931 - val_accuracy: 0.9683 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0927 - accuracy: 0.9666\n",
      "Epoch 24: saving model to modelos salvos\\melhor_modelo_fold02_epoch24.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9669 - val_loss: 0.0911 - val_accuracy: 0.9676 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9688 - val_loss: 0.0922 - val_accuracy: 0.9661 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0887 - accuracy: 0.9687\n",
      "Epoch 26: saving model to modelos salvos\\melhor_modelo_fold02_epoch26.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9691 - val_loss: 0.0881 - val_accuracy: 0.9683 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.0823 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0819 - accuracy: 0.9727\n",
      "Epoch 28: saving model to modelos salvos\\melhor_modelo_fold02_epoch28.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9726 - val_loss: 0.0806 - val_accuracy: 0.9749 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9735 - val_loss: 0.0804 - val_accuracy: 0.9739 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0802 - accuracy: 0.9739\n",
      "Epoch 30: saving model to modelos salvos\\melhor_modelo_fold02_epoch30.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9736 - val_loss: 0.0791 - val_accuracy: 0.9730 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.0781 - val_accuracy: 0.9772 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0770 - accuracy: 0.9751\n",
      "Epoch 32: saving model to modelos salvos\\melhor_modelo_fold02_epoch32.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9753 - val_loss: 0.0774 - val_accuracy: 0.9757 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.0778 - val_accuracy: 0.9738 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0752 - accuracy: 0.9751\n",
      "Epoch 34: saving model to modelos salvos\\melhor_modelo_fold02_epoch34.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9754 - val_loss: 0.0733 - val_accuracy: 0.9768 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9776 - val_loss: 0.0744 - val_accuracy: 0.9773 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0702 - accuracy: 0.9782\n",
      "Epoch 36: saving model to modelos salvos\\melhor_modelo_fold02_epoch36.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9780 - val_loss: 0.0694 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9786 - val_loss: 0.0679 - val_accuracy: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0678 - accuracy: 0.9794\n",
      "Epoch 38: saving model to modelos salvos\\melhor_modelo_fold02_epoch38.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 0.0683 - val_accuracy: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.0689 - val_accuracy: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0667 - accuracy: 0.9795\n",
      "Epoch 40: saving model to modelos salvos\\melhor_modelo_fold02_epoch40.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.0659 - val_accuracy: 0.9804 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9809 - val_loss: 0.0663 - val_accuracy: 0.9789 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0643 - accuracy: 0.9805\n",
      "Epoch 42: saving model to modelos salvos\\melhor_modelo_fold02_epoch42.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9813 - val_loss: 0.0634 - val_accuracy: 0.9800 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0626 - accuracy: 0.9809\n",
      "Epoch 44: saving model to modelos salvos\\melhor_modelo_fold02_epoch44.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0617 - val_accuracy: 0.9822 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9814 - val_loss: 0.0615 - val_accuracy: 0.9816 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0609 - accuracy: 0.9821\n",
      "Epoch 46: saving model to modelos salvos\\melhor_modelo_fold02_epoch46.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9819 - val_loss: 0.0609 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.0603 - val_accuracy: 0.9827 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0589 - accuracy: 0.9824\n",
      "Epoch 48: saving model to modelos salvos\\melhor_modelo_fold02_epoch48.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 0.0597 - val_accuracy: 0.9819 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9829 - val_loss: 0.0588 - val_accuracy: 0.9814 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0575 - accuracy: 0.9830\n",
      "Epoch 50: saving model to modelos salvos\\melhor_modelo_fold02_epoch50.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9829 - val_loss: 0.0571 - val_accuracy: 0.9832 - lr: 5.0000e-04\n",
      "1921/1921 [==============================] - 3s 2ms/step - loss: 0.0571 - accuracy: 0.9833\n",
      "metricas da fold: [0.05708928778767586, 0.9832549691200256]\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 7ms/step - loss: 0.6870 - accuracy: 0.8084 - val_loss: 0.2284 - val_accuracy: 0.9124 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.2119 - accuracy: 0.9231\n",
      "Epoch 2: saving model to modelos salvos\\melhor_modelo_fold03_epoch02.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.9234 - val_loss: 0.1967 - val_accuracy: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9329 - val_loss: 0.1797 - val_accuracy: 0.9358 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "35/50 [====================>.........] - ETA: 0s - loss: 0.1752 - accuracy: 0.9370\n",
      "Epoch 4: saving model to modelos salvos\\melhor_modelo_fold03_epoch04.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9377 - val_loss: 0.1658 - val_accuracy: 0.9389 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9407 - val_loss: 0.1548 - val_accuracy: 0.9460 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1538 - accuracy: 0.9436\n",
      "Epoch 6: saving model to modelos salvos\\melhor_modelo_fold03_epoch06.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9438 - val_loss: 0.1486 - val_accuracy: 0.9442 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9450 - val_loss: 0.1461 - val_accuracy: 0.9465 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1435 - accuracy: 0.9468\n",
      "Epoch 8: saving model to modelos salvos\\melhor_modelo_fold03_epoch08.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9472 - val_loss: 0.1365 - val_accuracy: 0.9488 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9492 - val_loss: 0.1307 - val_accuracy: 0.9495 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1313 - accuracy: 0.9506\n",
      "Epoch 10: saving model to modelos salvos\\melhor_modelo_fold03_epoch10.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9506 - val_loss: 0.1286 - val_accuracy: 0.9525 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9520 - val_loss: 0.1253 - val_accuracy: 0.9529 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.1239 - accuracy: 0.9534\n",
      "Epoch 12: saving model to modelos salvos\\melhor_modelo_fold03_epoch12.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9536 - val_loss: 0.1201 - val_accuracy: 0.9588 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9555 - val_loss: 0.1207 - val_accuracy: 0.9553 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1171 - accuracy: 0.9569\n",
      "Epoch 14: saving model to modelos salvos\\melhor_modelo_fold03_epoch14.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9574 - val_loss: 0.1110 - val_accuracy: 0.9585 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9586 - val_loss: 0.1103 - val_accuracy: 0.9583 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1092 - accuracy: 0.9594\n",
      "Epoch 16: saving model to modelos salvos\\melhor_modelo_fold03_epoch16.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9596 - val_loss: 0.1066 - val_accuracy: 0.9598 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9614 - val_loss: 0.1043 - val_accuracy: 0.9619 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1041 - accuracy: 0.9617\n",
      "Epoch 18: saving model to modelos salvos\\melhor_modelo_fold03_epoch18.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9617 - val_loss: 0.1005 - val_accuracy: 0.9628 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9632 - val_loss: 0.1009 - val_accuracy: 0.9625 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0994 - accuracy: 0.9643\n",
      "Epoch 20: saving model to modelos salvos\\melhor_modelo_fold03_epoch20.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9646 - val_loss: 0.0955 - val_accuracy: 0.9674 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9659 - val_loss: 0.0947 - val_accuracy: 0.9659 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0954 - accuracy: 0.9665\n",
      "Epoch 22: saving model to modelos salvos\\melhor_modelo_fold03_epoch22.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9672 - val_loss: 0.0918 - val_accuracy: 0.9692 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9692 - val_loss: 0.0897 - val_accuracy: 0.9707 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0887 - accuracy: 0.9704\n",
      "Epoch 24: saving model to modelos salvos\\melhor_modelo_fold03_epoch24.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9700 - val_loss: 0.0877 - val_accuracy: 0.9692 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9715 - val_loss: 0.0852 - val_accuracy: 0.9717 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0866 - accuracy: 0.9709\n",
      "Epoch 26: saving model to modelos salvos\\melhor_modelo_fold03_epoch26.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.0848 - val_accuracy: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.0897 - val_accuracy: 0.9703 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0829 - accuracy: 0.9726\n",
      "Epoch 28: saving model to modelos salvos\\melhor_modelo_fold03_epoch28.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9727 - val_loss: 0.0825 - val_accuracy: 0.9714 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9735 - val_loss: 0.0789 - val_accuracy: 0.9750 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0799 - accuracy: 0.9741\n",
      "Epoch 30: saving model to modelos salvos\\melhor_modelo_fold03_epoch30.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9741 - val_loss: 0.0784 - val_accuracy: 0.9749 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9752 - val_loss: 0.0777 - val_accuracy: 0.9756 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0772 - accuracy: 0.9751\n",
      "Epoch 32: saving model to modelos salvos\\melhor_modelo_fold03_epoch32.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9754 - val_loss: 0.0741 - val_accuracy: 0.9759 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9762 - val_loss: 0.0733 - val_accuracy: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0738 - accuracy: 0.9769\n",
      "Epoch 34: saving model to modelos salvos\\melhor_modelo_fold03_epoch34.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9770 - val_loss: 0.0786 - val_accuracy: 0.9743 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9771 - val_loss: 0.0734 - val_accuracy: 0.9758 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0722 - accuracy: 0.9770\n",
      "Epoch 36: saving model to modelos salvos\\melhor_modelo_fold03_epoch36.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9772 - val_loss: 0.0719 - val_accuracy: 0.9773 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.0727 - val_accuracy: 0.9750 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0699 - accuracy: 0.9779\n",
      "Epoch 38: saving model to modelos salvos\\melhor_modelo_fold03_epoch38.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.0673 - val_accuracy: 0.9790 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9773 - val_loss: 0.0708 - val_accuracy: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0672 - accuracy: 0.9791\n",
      "Epoch 40: saving model to modelos salvos\\melhor_modelo_fold03_epoch40.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0698 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.0648 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0649 - accuracy: 0.9804\n",
      "Epoch 42: saving model to modelos salvos\\melhor_modelo_fold03_epoch42.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9803 - val_loss: 0.0626 - val_accuracy: 0.9811 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.0667 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0635 - accuracy: 0.9805\n",
      "Epoch 44: saving model to modelos salvos\\melhor_modelo_fold03_epoch44.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9805 - val_loss: 0.0655 - val_accuracy: 0.9795 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9806 - val_loss: 0.0618 - val_accuracy: 0.9803 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0622 - accuracy: 0.9814\n",
      "Epoch 46: saving model to modelos salvos\\melhor_modelo_fold03_epoch46.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.0621 - val_accuracy: 0.9803 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.0627 - val_accuracy: 0.9793 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0603 - accuracy: 0.9819\n",
      "Epoch 48: saving model to modelos salvos\\melhor_modelo_fold03_epoch48.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9820 - val_loss: 0.0591 - val_accuracy: 0.9818 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.0593 - val_accuracy: 0.9819 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0585 - accuracy: 0.9827\n",
      "Epoch 50: saving model to modelos salvos\\melhor_modelo_fold03_epoch50.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9828 - val_loss: 0.0576 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
      "1921/1921 [==============================] - 3s 2ms/step - loss: 0.0576 - accuracy: 0.9826\n",
      "metricas da fold: [0.05756927281618118, 0.9825552105903625]\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 0.7992 - accuracy: 0.7936 - val_loss: 0.2397 - val_accuracy: 0.9114 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "35/50 [====================>.........] - ETA: 0s - loss: 0.2167 - accuracy: 0.9200\n",
      "Epoch 2: saving model to modelos salvos\\melhor_modelo_fold04_epoch02.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9225 - val_loss: 0.1989 - val_accuracy: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9330 - val_loss: 0.1834 - val_accuracy: 0.9342 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "36/50 [====================>.........] - ETA: 0s - loss: 0.1738 - accuracy: 0.9372\n",
      "Epoch 4: saving model to modelos salvos\\melhor_modelo_fold04_epoch04.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9378 - val_loss: 0.1667 - val_accuracy: 0.9378 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9412 - val_loss: 0.1577 - val_accuracy: 0.9410 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1520 - accuracy: 0.9429\n",
      "Epoch 6: saving model to modelos salvos\\melhor_modelo_fold04_epoch06.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9432 - val_loss: 0.1508 - val_accuracy: 0.9428 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9449 - val_loss: 0.1518 - val_accuracy: 0.9414 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9460\n",
      "Epoch 8: saving model to modelos salvos\\melhor_modelo_fold04_epoch08.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9461 - val_loss: 0.1412 - val_accuracy: 0.9456 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9478 - val_loss: 0.1368 - val_accuracy: 0.9476 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1319 - accuracy: 0.9489\n",
      "Epoch 10: saving model to modelos salvos\\melhor_modelo_fold04_epoch10.hdf5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9492 - val_loss: 0.1319 - val_accuracy: 0.9512 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9504 - val_loss: 0.1293 - val_accuracy: 0.9506 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1244 - accuracy: 0.9517\n",
      "Epoch 12: saving model to modelos salvos\\melhor_modelo_fold04_epoch12.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9517 - val_loss: 0.1254 - val_accuracy: 0.9526 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9532 - val_loss: 0.1225 - val_accuracy: 0.9532 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1193 - accuracy: 0.9545\n",
      "Epoch 14: saving model to modelos salvos\\melhor_modelo_fold04_epoch14.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9547 - val_loss: 0.1188 - val_accuracy: 0.9570 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9560 - val_loss: 0.1184 - val_accuracy: 0.9520 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1148 - accuracy: 0.9562\n",
      "Epoch 16: saving model to modelos salvos\\melhor_modelo_fold04_epoch16.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9566 - val_loss: 0.1142 - val_accuracy: 0.9587 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9579 - val_loss: 0.1144 - val_accuracy: 0.9585 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1091 - accuracy: 0.9596\n",
      "Epoch 18: saving model to modelos salvos\\melhor_modelo_fold04_epoch18.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9592 - val_loss: 0.1109 - val_accuracy: 0.9564 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9594 - val_loss: 0.1102 - val_accuracy: 0.9584 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.1057 - accuracy: 0.9601\n",
      "Epoch 20: saving model to modelos salvos\\melhor_modelo_fold04_epoch20.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9604 - val_loss: 0.1052 - val_accuracy: 0.9596 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9622 - val_loss: 0.1064 - val_accuracy: 0.9582 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1006 - accuracy: 0.9632\n",
      "Epoch 22: saving model to modelos salvos\\melhor_modelo_fold04_epoch22.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9629 - val_loss: 0.1042 - val_accuracy: 0.9601 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9637 - val_loss: 0.1012 - val_accuracy: 0.9601 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0977 - accuracy: 0.9642\n",
      "Epoch 24: saving model to modelos salvos\\melhor_modelo_fold04_epoch24.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9646 - val_loss: 0.0997 - val_accuracy: 0.9636 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9663 - val_loss: 0.0947 - val_accuracy: 0.9650 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0930 - accuracy: 0.9664\n",
      "Epoch 26: saving model to modelos salvos\\melhor_modelo_fold04_epoch26.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9668 - val_loss: 0.0923 - val_accuracy: 0.9684 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9685 - val_loss: 0.0912 - val_accuracy: 0.9672 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0884 - accuracy: 0.9691\n",
      "Epoch 28: saving model to modelos salvos\\melhor_modelo_fold04_epoch28.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9693 - val_loss: 0.0894 - val_accuracy: 0.9705 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9699 - val_loss: 0.0878 - val_accuracy: 0.9705 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0871 - accuracy: 0.9698\n",
      "Epoch 30: saving model to modelos salvos\\melhor_modelo_fold04_epoch30.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.0880 - val_accuracy: 0.9682 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9718 - val_loss: 0.0850 - val_accuracy: 0.9697 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0830 - accuracy: 0.9715\n",
      "Epoch 32: saving model to modelos salvos\\melhor_modelo_fold04_epoch32.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 0.0844 - val_accuracy: 0.9747 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9733 - val_loss: 0.0830 - val_accuracy: 0.9714 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0799 - accuracy: 0.9744\n",
      "Epoch 34: saving model to modelos salvos\\melhor_modelo_fold04_epoch34.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.0811 - val_accuracy: 0.9739 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.0780 - val_accuracy: 0.9753 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0762 - accuracy: 0.9756\n",
      "Epoch 36: saving model to modelos salvos\\melhor_modelo_fold04_epoch36.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9755 - val_loss: 0.0783 - val_accuracy: 0.9749 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9766 - val_loss: 0.0756 - val_accuracy: 0.9772 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0735 - accuracy: 0.9771\n",
      "Epoch 38: saving model to modelos salvos\\melhor_modelo_fold04_epoch38.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0792 - val_accuracy: 0.9742 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9775 - val_loss: 0.0740 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0715 - accuracy: 0.9782\n",
      "Epoch 40: saving model to modelos salvos\\melhor_modelo_fold04_epoch40.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9782 - val_loss: 0.0715 - val_accuracy: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9780 - val_loss: 0.0718 - val_accuracy: 0.9790 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0693 - accuracy: 0.9789\n",
      "Epoch 42: saving model to modelos salvos\\melhor_modelo_fold04_epoch42.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.0690 - val_accuracy: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.0689 - val_accuracy: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0680 - accuracy: 0.9796\n",
      "Epoch 44: saving model to modelos salvos\\melhor_modelo_fold04_epoch44.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9798 - val_loss: 0.0702 - val_accuracy: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9799 - val_loss: 0.0665 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0652 - accuracy: 0.9804\n",
      "Epoch 46: saving model to modelos salvos\\melhor_modelo_fold04_epoch46.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9802 - val_loss: 0.0661 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9813 - val_loss: 0.0675 - val_accuracy: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0637 - accuracy: 0.9814\n",
      "Epoch 48: saving model to modelos salvos\\melhor_modelo_fold04_epoch48.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9814 - val_loss: 0.0645 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9817 - val_loss: 0.0623 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0614 - accuracy: 0.9824\n",
      "Epoch 50: saving model to modelos salvos\\melhor_modelo_fold04_epoch50.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9823 - val_loss: 0.0665 - val_accuracy: 0.9792 - lr: 5.0000e-04\n",
      "1921/1921 [==============================] - 3s 2ms/step - loss: 0.0665 - accuracy: 0.9792\n",
      "metricas da fold: [0.06653221696615219, 0.9791866540908813]\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 1.0031 - accuracy: 0.7543 - val_loss: 0.2565 - val_accuracy: 0.9065 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "35/50 [====================>.........] - ETA: 0s - loss: 0.2292 - accuracy: 0.9175\n",
      "Epoch 2: saving model to modelos salvos\\melhor_modelo_fold05_epoch02.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9208 - val_loss: 0.2074 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9309 - val_loss: 0.1868 - val_accuracy: 0.9338 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "34/50 [===================>..........] - ETA: 0s - loss: 0.1823 - accuracy: 0.9344\n",
      "Epoch 4: saving model to modelos salvos\\melhor_modelo_fold05_epoch04.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1799 - accuracy: 0.9348 - val_loss: 0.1761 - val_accuracy: 0.9364 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9384 - val_loss: 0.1678 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1618 - accuracy: 0.9407\n",
      "Epoch 6: saving model to modelos salvos\\melhor_modelo_fold05_epoch06.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9410 - val_loss: 0.1589 - val_accuracy: 0.9400 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9435 - val_loss: 0.1506 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9460\n",
      "Epoch 8: saving model to modelos salvos\\melhor_modelo_fold05_epoch08.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9458 - val_loss: 0.1443 - val_accuracy: 0.9481 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9472 - val_loss: 0.1405 - val_accuracy: 0.9454 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1366 - accuracy: 0.9485\n",
      "Epoch 10: saving model to modelos salvos\\melhor_modelo_fold05_epoch10.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9483 - val_loss: 0.1357 - val_accuracy: 0.9506 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9502 - val_loss: 0.1297 - val_accuracy: 0.9494 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1286 - accuracy: 0.9512\n",
      "Epoch 12: saving model to modelos salvos\\melhor_modelo_fold05_epoch12.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9516 - val_loss: 0.1256 - val_accuracy: 0.9533 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9525 - val_loss: 0.1239 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.1218 - accuracy: 0.9544\n",
      "Epoch 14: saving model to modelos salvos\\melhor_modelo_fold05_epoch14.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9544 - val_loss: 0.1193 - val_accuracy: 0.9543 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9559 - val_loss: 0.1184 - val_accuracy: 0.9558 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1153 - accuracy: 0.9570\n",
      "Epoch 16: saving model to modelos salvos\\melhor_modelo_fold05_epoch16.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9570 - val_loss: 0.1151 - val_accuracy: 0.9568 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9583 - val_loss: 0.1131 - val_accuracy: 0.9567 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1113 - accuracy: 0.9587\n",
      "Epoch 18: saving model to modelos salvos\\melhor_modelo_fold05_epoch18.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9590 - val_loss: 0.1097 - val_accuracy: 0.9612 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9605 - val_loss: 0.1066 - val_accuracy: 0.9606 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1048 - accuracy: 0.9619\n",
      "Epoch 20: saving model to modelos salvos\\melhor_modelo_fold05_epoch20.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9616 - val_loss: 0.1037 - val_accuracy: 0.9631 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9623 - val_loss: 0.1041 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.1026 - accuracy: 0.9621\n",
      "Epoch 22: saving model to modelos salvos\\melhor_modelo_fold05_epoch22.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9625 - val_loss: 0.1005 - val_accuracy: 0.9641 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9641 - val_loss: 0.0980 - val_accuracy: 0.9666 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0977 - accuracy: 0.9651\n",
      "Epoch 24: saving model to modelos salvos\\melhor_modelo_fold05_epoch24.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9652 - val_loss: 0.1003 - val_accuracy: 0.9610 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.0949 - val_accuracy: 0.9653 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0943 - accuracy: 0.9663\n",
      "Epoch 26: saving model to modelos salvos\\melhor_modelo_fold05_epoch26.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.0929 - val_accuracy: 0.9657 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9685 - val_loss: 0.0912 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0901 - accuracy: 0.9688\n",
      "Epoch 28: saving model to modelos salvos\\melhor_modelo_fold05_epoch28.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9692 - val_loss: 0.0901 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9697 - val_loss: 0.0861 - val_accuracy: 0.9705 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0862 - accuracy: 0.9707\n",
      "Epoch 30: saving model to modelos salvos\\melhor_modelo_fold05_epoch30.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9707 - val_loss: 0.0901 - val_accuracy: 0.9657 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9711 - val_loss: 0.0837 - val_accuracy: 0.9720 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0832 - accuracy: 0.9717\n",
      "Epoch 32: saving model to modelos salvos\\melhor_modelo_fold05_epoch32.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9721 - val_loss: 0.0837 - val_accuracy: 0.9710 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9724 - val_loss: 0.0802 - val_accuracy: 0.9745 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0802 - accuracy: 0.9734\n",
      "Epoch 34: saving model to modelos salvos\\melhor_modelo_fold05_epoch34.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9737 - val_loss: 0.0781 - val_accuracy: 0.9750 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9744 - val_loss: 0.0771 - val_accuracy: 0.9746 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0769 - accuracy: 0.9748\n",
      "Epoch 36: saving model to modelos salvos\\melhor_modelo_fold05_epoch36.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9746 - val_loss: 0.0759 - val_accuracy: 0.9755 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9754 - val_loss: 0.0768 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0740 - accuracy: 0.9762\n",
      "Epoch 38: saving model to modelos salvos\\melhor_modelo_fold05_epoch38.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9763 - val_loss: 0.0767 - val_accuracy: 0.9751 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 0.0726 - val_accuracy: 0.9773 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0726 - accuracy: 0.9769\n",
      "Epoch 40: saving model to modelos salvos\\melhor_modelo_fold05_epoch40.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.0741 - val_accuracy: 0.9748 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9768 - val_loss: 0.0696 - val_accuracy: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9780\n",
      "Epoch 42: saving model to modelos salvos\\melhor_modelo_fold05_epoch42.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9774 - val_loss: 0.0744 - val_accuracy: 0.9738 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9770 - val_loss: 0.0689 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "37/50 [=====================>........] - ETA: 0s - loss: 0.0685 - accuracy: 0.9783\n",
      "Epoch 44: saving model to modelos salvos\\melhor_modelo_fold05_epoch44.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.0681 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 0.0663 - val_accuracy: 0.9802 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0666 - accuracy: 0.9795\n",
      "Epoch 46: saving model to modelos salvos\\melhor_modelo_fold05_epoch46.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9795 - val_loss: 0.0662 - val_accuracy: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9797 - val_loss: 0.0665 - val_accuracy: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "39/50 [======================>.......] - ETA: 0s - loss: 0.0645 - accuracy: 0.9801\n",
      "Epoch 48: saving model to modelos salvos\\melhor_modelo_fold05_epoch48.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9802 - val_loss: 0.0633 - val_accuracy: 0.9811 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9809 - val_loss: 0.0651 - val_accuracy: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "38/50 [=====================>........] - ETA: 0s - loss: 0.0639 - accuracy: 0.9805\n",
      "Epoch 50: saving model to modelos salvos\\melhor_modelo_fold05_epoch50.hdf5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9806 - val_loss: 0.0632 - val_accuracy: 0.9800 - lr: 5.0000e-04\n",
      "1921/1921 [==============================] - 3s 2ms/step - loss: 0.0632 - accuracy: 0.9799\n",
      "metricas da fold: [0.06320793181657791, 0.9799352288246155]\n"
     ]
    }
   ],
   "source": [
    "# treinamento\n",
    "fold_num = 1\n",
    "\n",
    "for index_treino, index_teste in kf.split(X):\n",
    "    X_treino, X_teste = X.iloc[index_treino], X.iloc[index_teste]\n",
    "    Y_treino, Y_teste = Y.iloc[index_treino], Y.iloc[index_teste]\n",
    "\n",
    "    model = MLP()\n",
    "\n",
    "    checkpoint = create_checkpoint(fold_num)\n",
    "\n",
    "    model.fit(X_treino,\n",
    "              Y_treino, \n",
    "              epochs=epocas,\n",
    "              batch_size=batch, \n",
    "              validation_data=(X_teste, Y_teste), \n",
    "              callbacks=[checkpoint, reduce_lr])\n",
    "\n",
    "    scores = model.evaluate(X_teste, Y_teste)\n",
    "    print(f\"metricas da fold: {scores}\")\n",
    "\n",
    "    fold_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>4 - Validaçao da RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = dados_validacao[['A', 'B', 'C', 'D']]\n",
    "Y_teste = dados_validacao[POSICAO_df.columns]\n",
    "\n",
    "Y_teste_classes = np.argmax(Y_teste.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341/1341 [==============================] - 1s 750us/step\n",
      "1341/1341 [==============================] - 1s 790us/step\n",
      "1341/1341 [==============================] - 1s 1ms/step\n",
      "1341/1341 [==============================] - 1s 1ms/step\n",
      "1341/1341 [==============================] - 1s 924us/step\n",
      "1341/1341 [==============================] - 1s 841us/step\n",
      "1341/1341 [==============================] - 1s 858us/step\n",
      "1341/1341 [==============================] - 1s 840us/step\n",
      "1341/1341 [==============================] - 1s 837us/step\n",
      "1341/1341 [==============================] - 1s 875us/step\n",
      "1341/1341 [==============================] - 1s 836us/step\n",
      "1341/1341 [==============================] - 1s 854us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 837us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 844us/step\n",
      "1341/1341 [==============================] - 1s 841us/step\n",
      "1341/1341 [==============================] - 1s 833us/step\n",
      "1341/1341 [==============================] - 1s 844us/step\n",
      "1341/1341 [==============================] - 1s 838us/step\n",
      "1341/1341 [==============================] - 1s 838us/step\n",
      "1341/1341 [==============================] - 1s 860us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 838us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 830us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 834us/step\n",
      "1341/1341 [==============================] - 1s 845us/step\n",
      "1341/1341 [==============================] - 1s 840us/step\n",
      "1341/1341 [==============================] - 1s 843us/step\n",
      "1341/1341 [==============================] - 1s 847us/step\n",
      "1341/1341 [==============================] - 1s 840us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 840us/step\n",
      "1341/1341 [==============================] - 1s 844us/step\n",
      "1341/1341 [==============================] - 1s 871us/step\n",
      "1341/1341 [==============================] - 1s 836us/step\n",
      "1341/1341 [==============================] - 1s 831us/step\n",
      "1341/1341 [==============================] - 1s 848us/step\n",
      "1341/1341 [==============================] - 1s 842us/step\n",
      "1341/1341 [==============================] - 1s 824us/step\n",
      "1341/1341 [==============================] - 1s 853us/step\n",
      "1341/1341 [==============================] - 1s 842us/step\n",
      "1341/1341 [==============================] - 1s 842us/step\n",
      "1341/1341 [==============================] - 1s 847us/step\n",
      "1341/1341 [==============================] - 1s 827us/step\n",
      "1341/1341 [==============================] - 1s 979us/step\n",
      "1341/1341 [==============================] - 1s 972us/step\n",
      "1341/1341 [==============================] - 1s 965us/step\n",
      "1341/1341 [==============================] - 1s 833us/step\n",
      "1341/1341 [==============================] - 1s 895us/step\n",
      "1341/1341 [==============================] - 1s 830us/step\n",
      "1341/1341 [==============================] - 1s 864us/step\n",
      "1341/1341 [==============================] - 1s 827us/step\n",
      "1341/1341 [==============================] - 1s 844us/step\n",
      "1341/1341 [==============================] - 1s 837us/step\n",
      "1341/1341 [==============================] - 1s 862us/step\n",
      "1341/1341 [==============================] - 1s 854us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 827us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 840us/step\n",
      "1341/1341 [==============================] - 1s 848us/step\n",
      "1341/1341 [==============================] - 1s 857us/step\n",
      "1341/1341 [==============================] - 1s 833us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 830us/step\n",
      "1341/1341 [==============================] - 1s 848us/step\n",
      "1341/1341 [==============================] - 1s 833us/step\n",
      "1341/1341 [==============================] - 1s 850us/step\n",
      "1341/1341 [==============================] - 1s 836us/step\n",
      "1341/1341 [==============================] - 1s 864us/step\n",
      "1341/1341 [==============================] - 1s 860us/step\n",
      "1341/1341 [==============================] - 1s 860us/step\n",
      "1341/1341 [==============================] - 1s 841us/step\n",
      "1341/1341 [==============================] - 1s 830us/step\n",
      "1341/1341 [==============================] - 1s 863us/step\n",
      "1341/1341 [==============================] - 1s 831us/step\n",
      "1341/1341 [==============================] - 1s 838us/step\n",
      "1341/1341 [==============================] - 1s 828us/step\n",
      "1341/1341 [==============================] - 1s 838us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 843us/step\n",
      "1341/1341 [==============================] - 1s 832us/step\n",
      "1341/1341 [==============================] - 1s 846us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 823us/step\n",
      "1341/1341 [==============================] - 1s 837us/step\n",
      "1341/1341 [==============================] - 1s 839us/step\n",
      "1341/1341 [==============================] - 1s 819us/step\n",
      "1341/1341 [==============================] - 1s 841us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 1ms/step\n",
      "1341/1341 [==============================] - 1s 897us/step\n",
      "1341/1341 [==============================] - 1s 825us/step\n",
      "1341/1341 [==============================] - 1s 841us/step\n",
      "1341/1341 [==============================] - 1s 830us/step\n",
      "1341/1341 [==============================] - 1s 842us/step\n",
      "1341/1341 [==============================] - 1s 836us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 834us/step\n",
      "1341/1341 [==============================] - 1s 837us/step\n",
      "1341/1341 [==============================] - 1s 856us/step\n",
      "1341/1341 [==============================] - 1s 828us/step\n",
      "1341/1341 [==============================] - 1s 828us/step\n",
      "1341/1341 [==============================] - 1s 823us/step\n",
      "1341/1341 [==============================] - 1s 819us/step\n",
      "1341/1341 [==============================] - 1s 845us/step\n",
      "1341/1341 [==============================] - 1s 835us/step\n",
      "1341/1341 [==============================] - 1s 817us/step\n",
      "1341/1341 [==============================] - 1s 855us/step\n",
      "1341/1341 [==============================] - 1s 829us/step\n",
      "1341/1341 [==============================] - 1s 842us/step\n",
      "1341/1341 [==============================] - 1s 920us/step\n",
      "1341/1341 [==============================] - 1s 895us/step\n",
      "1341/1341 [==============================] - 1s 930us/step\n",
      "1341/1341 [==============================] - 1s 902us/step\n",
      "1341/1341 [==============================] - 1s 921us/step\n",
      "1341/1341 [==============================] - 1s 910us/step\n",
      "1341/1341 [==============================] - 1s 941us/step\n",
      "1341/1341 [==============================] - 1s 900us/step\n",
      "1341/1341 [==============================] - 1s 935us/step\n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for fold_num in range(1, folds+1):\n",
    "    for epoch in range(2, epocas + 1, 2):\n",
    "        modelo_validacao = MLP()\n",
    "        try:\n",
    "            modelo_validacao.load_weights(f'modelos salvos/melhor_modelo_fold{fold_num:02d}_epoch{epoch:02d}.hdf5')\n",
    "\n",
    "            Y_pred = modelo_validacao.predict(X_teste)\n",
    "            Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "            metricas = {\n",
    "                'fold': fold_num,\n",
    "                'epoch': epoch,\n",
    "                'acuracia': accuracy_score(Y_teste_classes, Y_pred_classes),\n",
    "                'precisao': precision_score(Y_teste_classes, Y_pred_classes, average='macro'),\n",
    "                'recall': recall_score(Y_teste_classes, Y_pred_classes, average='macro'),\n",
    "                'f1-score': f1_score(Y_teste_classes, Y_pred_classes, average='macro')\n",
    "            }\n",
    "            resultados.append(metricas)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Modelo para fold {fold_num} e epoch {epoch} não encontrado.\")\n",
    "\n",
    "# salvando os resultados em um csv para analise\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "resultados_df.to_csv('resultados.csv', sep = ';', index = False ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_29873_row0_col0, #T_29873_row0_col1, #T_29873_row0_col2, #T_29873_row0_col3, #T_29873_row0_col4, #T_29873_row0_col5, #T_29873_row25_col0, #T_29873_row25_col1, #T_29873_row25_col2, #T_29873_row25_col3, #T_29873_row25_col4, #T_29873_row25_col5, #T_29873_row75_col0, #T_29873_row75_col1, #T_29873_row75_col2, #T_29873_row75_col3, #T_29873_row75_col4, #T_29873_row75_col5, #T_29873_row100_col0, #T_29873_row100_col1, #T_29873_row100_col2, #T_29873_row100_col3, #T_29873_row100_col4, #T_29873_row100_col5 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_29873\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_29873_level0_col0\" class=\"col_heading level0 col0\" >fold</th>\n",
       "      <th id=\"T_29873_level0_col1\" class=\"col_heading level0 col1\" >epoch</th>\n",
       "      <th id=\"T_29873_level0_col2\" class=\"col_heading level0 col2\" >acuracia</th>\n",
       "      <th id=\"T_29873_level0_col3\" class=\"col_heading level0 col3\" >precisao</th>\n",
       "      <th id=\"T_29873_level0_col4\" class=\"col_heading level0 col4\" >recall</th>\n",
       "      <th id=\"T_29873_level0_col5\" class=\"col_heading level0 col5\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_29873_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_29873_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_29873_row0_col2\" class=\"data row0 col2\" >0.956369</td>\n",
       "      <td id=\"T_29873_row0_col3\" class=\"data row0 col3\" >0.956148</td>\n",
       "      <td id=\"T_29873_row0_col4\" class=\"data row0 col4\" >0.965818</td>\n",
       "      <td id=\"T_29873_row0_col5\" class=\"data row0 col5\" >0.959980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_29873_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_29873_row1_col1\" class=\"data row1 col1\" >4</td>\n",
       "      <td id=\"T_29873_row1_col2\" class=\"data row1 col2\" >0.925580</td>\n",
       "      <td id=\"T_29873_row1_col3\" class=\"data row1 col3\" >0.938530</td>\n",
       "      <td id=\"T_29873_row1_col4\" class=\"data row1 col4\" >0.942692</td>\n",
       "      <td id=\"T_29873_row1_col5\" class=\"data row1 col5\" >0.938320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_29873_row2_col0\" class=\"data row2 col0\" >1</td>\n",
       "      <td id=\"T_29873_row2_col1\" class=\"data row2 col1\" >6</td>\n",
       "      <td id=\"T_29873_row2_col2\" class=\"data row2 col2\" >0.936721</td>\n",
       "      <td id=\"T_29873_row2_col3\" class=\"data row2 col3\" >0.948838</td>\n",
       "      <td id=\"T_29873_row2_col4\" class=\"data row2 col4\" >0.956174</td>\n",
       "      <td id=\"T_29873_row2_col5\" class=\"data row2 col5\" >0.950672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_29873_row3_col0\" class=\"data row3 col0\" >1</td>\n",
       "      <td id=\"T_29873_row3_col1\" class=\"data row3 col1\" >8</td>\n",
       "      <td id=\"T_29873_row3_col2\" class=\"data row3 col2\" >0.940986</td>\n",
       "      <td id=\"T_29873_row3_col3\" class=\"data row3 col3\" >0.951882</td>\n",
       "      <td id=\"T_29873_row3_col4\" class=\"data row3 col4\" >0.957684</td>\n",
       "      <td id=\"T_29873_row3_col5\" class=\"data row3 col5\" >0.953745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_29873_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_29873_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "      <td id=\"T_29873_row4_col2\" class=\"data row4 col2\" >0.935532</td>\n",
       "      <td id=\"T_29873_row4_col3\" class=\"data row4 col3\" >0.947082</td>\n",
       "      <td id=\"T_29873_row4_col4\" class=\"data row4 col4\" >0.955537</td>\n",
       "      <td id=\"T_29873_row4_col5\" class=\"data row4 col5\" >0.949140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_29873_row5_col0\" class=\"data row5 col0\" >1</td>\n",
       "      <td id=\"T_29873_row5_col1\" class=\"data row5 col1\" >12</td>\n",
       "      <td id=\"T_29873_row5_col2\" class=\"data row5 col2\" >0.913973</td>\n",
       "      <td id=\"T_29873_row5_col3\" class=\"data row5 col3\" >0.931226</td>\n",
       "      <td id=\"T_29873_row5_col4\" class=\"data row5 col4\" >0.935410</td>\n",
       "      <td id=\"T_29873_row5_col5\" class=\"data row5 col5\" >0.929961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_29873_row6_col0\" class=\"data row6 col0\" >1</td>\n",
       "      <td id=\"T_29873_row6_col1\" class=\"data row6 col1\" >14</td>\n",
       "      <td id=\"T_29873_row6_col2\" class=\"data row6 col2\" >0.910150</td>\n",
       "      <td id=\"T_29873_row6_col3\" class=\"data row6 col3\" >0.928501</td>\n",
       "      <td id=\"T_29873_row6_col4\" class=\"data row6 col4\" >0.933273</td>\n",
       "      <td id=\"T_29873_row6_col5\" class=\"data row6 col5\" >0.927197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_29873_row7_col0\" class=\"data row7 col0\" >1</td>\n",
       "      <td id=\"T_29873_row7_col1\" class=\"data row7 col1\" >16</td>\n",
       "      <td id=\"T_29873_row7_col2\" class=\"data row7 col2\" >0.921990</td>\n",
       "      <td id=\"T_29873_row7_col3\" class=\"data row7 col3\" >0.937269</td>\n",
       "      <td id=\"T_29873_row7_col4\" class=\"data row7 col4\" >0.940429</td>\n",
       "      <td id=\"T_29873_row7_col5\" class=\"data row7 col5\" >0.936555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_29873_row8_col0\" class=\"data row8 col0\" >1</td>\n",
       "      <td id=\"T_29873_row8_col1\" class=\"data row8 col1\" >18</td>\n",
       "      <td id=\"T_29873_row8_col2\" class=\"data row8 col2\" >0.917329</td>\n",
       "      <td id=\"T_29873_row8_col3\" class=\"data row8 col3\" >0.934466</td>\n",
       "      <td id=\"T_29873_row8_col4\" class=\"data row8 col4\" >0.936095</td>\n",
       "      <td id=\"T_29873_row8_col5\" class=\"data row8 col5\" >0.932186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_29873_row9_col0\" class=\"data row9 col0\" >1</td>\n",
       "      <td id=\"T_29873_row9_col1\" class=\"data row9 col1\" >20</td>\n",
       "      <td id=\"T_29873_row9_col2\" class=\"data row9 col2\" >0.916653</td>\n",
       "      <td id=\"T_29873_row9_col3\" class=\"data row9 col3\" >0.933434</td>\n",
       "      <td id=\"T_29873_row9_col4\" class=\"data row9 col4\" >0.937844</td>\n",
       "      <td id=\"T_29873_row9_col5\" class=\"data row9 col5\" >0.932818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_29873_row10_col0\" class=\"data row10 col0\" >1</td>\n",
       "      <td id=\"T_29873_row10_col1\" class=\"data row10 col1\" >22</td>\n",
       "      <td id=\"T_29873_row10_col2\" class=\"data row10 col2\" >0.905093</td>\n",
       "      <td id=\"T_29873_row10_col3\" class=\"data row10 col3\" >0.926769</td>\n",
       "      <td id=\"T_29873_row10_col4\" class=\"data row10 col4\" >0.926113</td>\n",
       "      <td id=\"T_29873_row10_col5\" class=\"data row10 col5\" >0.923107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_29873_row11_col0\" class=\"data row11 col0\" >1</td>\n",
       "      <td id=\"T_29873_row11_col1\" class=\"data row11 col1\" >24</td>\n",
       "      <td id=\"T_29873_row11_col2\" class=\"data row11 col2\" >0.908169</td>\n",
       "      <td id=\"T_29873_row11_col3\" class=\"data row11 col3\" >0.926952</td>\n",
       "      <td id=\"T_29873_row11_col4\" class=\"data row11 col4\" >0.930254</td>\n",
       "      <td id=\"T_29873_row11_col5\" class=\"data row11 col5\" >0.924736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_29873_row12_col0\" class=\"data row12 col0\" >1</td>\n",
       "      <td id=\"T_29873_row12_col1\" class=\"data row12 col1\" >26</td>\n",
       "      <td id=\"T_29873_row12_col2\" class=\"data row12 col2\" >0.905769</td>\n",
       "      <td id=\"T_29873_row12_col3\" class=\"data row12 col3\" >0.925964</td>\n",
       "      <td id=\"T_29873_row12_col4\" class=\"data row12 col4\" >0.928024</td>\n",
       "      <td id=\"T_29873_row12_col5\" class=\"data row12 col5\" >0.923106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_29873_row13_col0\" class=\"data row13 col0\" >1</td>\n",
       "      <td id=\"T_29873_row13_col1\" class=\"data row13 col1\" >28</td>\n",
       "      <td id=\"T_29873_row13_col2\" class=\"data row13 col2\" >0.911689</td>\n",
       "      <td id=\"T_29873_row13_col3\" class=\"data row13 col3\" >0.928806</td>\n",
       "      <td id=\"T_29873_row13_col4\" class=\"data row13 col4\" >0.933322</td>\n",
       "      <td id=\"T_29873_row13_col5\" class=\"data row13 col5\" >0.928188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_29873_row14_col0\" class=\"data row14 col0\" >1</td>\n",
       "      <td id=\"T_29873_row14_col1\" class=\"data row14 col1\" >30</td>\n",
       "      <td id=\"T_29873_row14_col2\" class=\"data row14 col2\" >0.906375</td>\n",
       "      <td id=\"T_29873_row14_col3\" class=\"data row14 col3\" >0.927332</td>\n",
       "      <td id=\"T_29873_row14_col4\" class=\"data row14 col4\" >0.927326</td>\n",
       "      <td id=\"T_29873_row14_col5\" class=\"data row14 col5\" >0.923643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_29873_row15_col0\" class=\"data row15 col0\" >1</td>\n",
       "      <td id=\"T_29873_row15_col1\" class=\"data row15 col1\" >32</td>\n",
       "      <td id=\"T_29873_row15_col2\" class=\"data row15 col2\" >0.896236</td>\n",
       "      <td id=\"T_29873_row15_col3\" class=\"data row15 col3\" >0.918176</td>\n",
       "      <td id=\"T_29873_row15_col4\" class=\"data row15 col4\" >0.920395</td>\n",
       "      <td id=\"T_29873_row15_col5\" class=\"data row15 col5\" >0.916060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_29873_row16_col0\" class=\"data row16 col0\" >1</td>\n",
       "      <td id=\"T_29873_row16_col1\" class=\"data row16 col1\" >34</td>\n",
       "      <td id=\"T_29873_row16_col2\" class=\"data row16 col2\" >0.897378</td>\n",
       "      <td id=\"T_29873_row16_col3\" class=\"data row16 col3\" >0.917023</td>\n",
       "      <td id=\"T_29873_row16_col4\" class=\"data row16 col4\" >0.921365</td>\n",
       "      <td id=\"T_29873_row16_col5\" class=\"data row16 col5\" >0.915131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_29873_row17_col0\" class=\"data row17 col0\" >1</td>\n",
       "      <td id=\"T_29873_row17_col1\" class=\"data row17 col1\" >36</td>\n",
       "      <td id=\"T_29873_row17_col2\" class=\"data row17 col2\" >0.896772</td>\n",
       "      <td id=\"T_29873_row17_col3\" class=\"data row17 col3\" >0.919563</td>\n",
       "      <td id=\"T_29873_row17_col4\" class=\"data row17 col4\" >0.919549</td>\n",
       "      <td id=\"T_29873_row17_col5\" class=\"data row17 col5\" >0.915636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_29873_row18_col0\" class=\"data row18 col0\" >1</td>\n",
       "      <td id=\"T_29873_row18_col1\" class=\"data row18 col1\" >38</td>\n",
       "      <td id=\"T_29873_row18_col2\" class=\"data row18 col2\" >0.891924</td>\n",
       "      <td id=\"T_29873_row18_col3\" class=\"data row18 col3\" >0.914437</td>\n",
       "      <td id=\"T_29873_row18_col4\" class=\"data row18 col4\" >0.915437</td>\n",
       "      <td id=\"T_29873_row18_col5\" class=\"data row18 col5\" >0.911186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_29873_row19_col0\" class=\"data row19 col0\" >1</td>\n",
       "      <td id=\"T_29873_row19_col1\" class=\"data row19 col1\" >40</td>\n",
       "      <td id=\"T_29873_row19_col2\" class=\"data row19 col2\" >0.904790</td>\n",
       "      <td id=\"T_29873_row19_col3\" class=\"data row19 col3\" >0.924994</td>\n",
       "      <td id=\"T_29873_row19_col4\" class=\"data row19 col4\" >0.924958</td>\n",
       "      <td id=\"T_29873_row19_col5\" class=\"data row19 col5\" >0.922147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_29873_row20_col0\" class=\"data row20 col0\" >1</td>\n",
       "      <td id=\"T_29873_row20_col1\" class=\"data row20 col1\" >42</td>\n",
       "      <td id=\"T_29873_row20_col2\" class=\"data row20 col2\" >0.901969</td>\n",
       "      <td id=\"T_29873_row20_col3\" class=\"data row20 col3\" >0.922824</td>\n",
       "      <td id=\"T_29873_row20_col4\" class=\"data row20 col4\" >0.924496</td>\n",
       "      <td id=\"T_29873_row20_col5\" class=\"data row20 col5\" >0.919974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_29873_row21_col0\" class=\"data row21 col0\" >1</td>\n",
       "      <td id=\"T_29873_row21_col1\" class=\"data row21 col1\" >44</td>\n",
       "      <td id=\"T_29873_row21_col2\" class=\"data row21 col2\" >0.889873</td>\n",
       "      <td id=\"T_29873_row21_col3\" class=\"data row21 col3\" >0.911099</td>\n",
       "      <td id=\"T_29873_row21_col4\" class=\"data row21 col4\" >0.914757</td>\n",
       "      <td id=\"T_29873_row21_col5\" class=\"data row21 col5\" >0.909237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_29873_row22_col0\" class=\"data row22 col0\" >1</td>\n",
       "      <td id=\"T_29873_row22_col1\" class=\"data row22 col1\" >46</td>\n",
       "      <td id=\"T_29873_row22_col2\" class=\"data row22 col2\" >0.889453</td>\n",
       "      <td id=\"T_29873_row22_col3\" class=\"data row22 col3\" >0.912405</td>\n",
       "      <td id=\"T_29873_row22_col4\" class=\"data row22 col4\" >0.912626</td>\n",
       "      <td id=\"T_29873_row22_col5\" class=\"data row22 col5\" >0.908536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_29873_row23_col0\" class=\"data row23 col0\" >1</td>\n",
       "      <td id=\"T_29873_row23_col1\" class=\"data row23 col1\" >48</td>\n",
       "      <td id=\"T_29873_row23_col2\" class=\"data row23 col2\" >0.884862</td>\n",
       "      <td id=\"T_29873_row23_col3\" class=\"data row23 col3\" >0.912017</td>\n",
       "      <td id=\"T_29873_row23_col4\" class=\"data row23 col4\" >0.908841</td>\n",
       "      <td id=\"T_29873_row23_col5\" class=\"data row23 col5\" >0.906068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_29873_row24_col0\" class=\"data row24 col0\" >1</td>\n",
       "      <td id=\"T_29873_row24_col1\" class=\"data row24 col1\" >50</td>\n",
       "      <td id=\"T_29873_row24_col2\" class=\"data row24 col2\" >0.885212</td>\n",
       "      <td id=\"T_29873_row24_col3\" class=\"data row24 col3\" >0.908858</td>\n",
       "      <td id=\"T_29873_row24_col4\" class=\"data row24 col4\" >0.910051</td>\n",
       "      <td id=\"T_29873_row24_col5\" class=\"data row24 col5\" >0.904669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_29873_row25_col0\" class=\"data row25 col0\" >2</td>\n",
       "      <td id=\"T_29873_row25_col1\" class=\"data row25 col1\" >2</td>\n",
       "      <td id=\"T_29873_row25_col2\" class=\"data row25 col2\" >0.951544</td>\n",
       "      <td id=\"T_29873_row25_col3\" class=\"data row25 col3\" >0.960699</td>\n",
       "      <td id=\"T_29873_row25_col4\" class=\"data row25 col4\" >0.965934</td>\n",
       "      <td id=\"T_29873_row25_col5\" class=\"data row25 col5\" >0.962451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_29873_row26_col0\" class=\"data row26 col0\" >2</td>\n",
       "      <td id=\"T_29873_row26_col1\" class=\"data row26 col1\" >4</td>\n",
       "      <td id=\"T_29873_row26_col2\" class=\"data row26 col2\" >0.936488</td>\n",
       "      <td id=\"T_29873_row26_col3\" class=\"data row26 col3\" >0.947744</td>\n",
       "      <td id=\"T_29873_row26_col4\" class=\"data row26 col4\" >0.954924</td>\n",
       "      <td id=\"T_29873_row26_col5\" class=\"data row26 col5\" >0.949932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_29873_row27_col0\" class=\"data row27 col0\" >2</td>\n",
       "      <td id=\"T_29873_row27_col1\" class=\"data row27 col1\" >6</td>\n",
       "      <td id=\"T_29873_row27_col2\" class=\"data row27 col2\" >0.929122</td>\n",
       "      <td id=\"T_29873_row27_col3\" class=\"data row27 col3\" >0.942468</td>\n",
       "      <td id=\"T_29873_row27_col4\" class=\"data row27 col4\" >0.948545</td>\n",
       "      <td id=\"T_29873_row27_col5\" class=\"data row27 col5\" >0.943807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_29873_row28_col0\" class=\"data row28 col0\" >2</td>\n",
       "      <td id=\"T_29873_row28_col1\" class=\"data row28 col1\" >8</td>\n",
       "      <td id=\"T_29873_row28_col2\" class=\"data row28 col2\" >0.931337</td>\n",
       "      <td id=\"T_29873_row28_col3\" class=\"data row28 col3\" >0.945095</td>\n",
       "      <td id=\"T_29873_row28_col4\" class=\"data row28 col4\" >0.950348</td>\n",
       "      <td id=\"T_29873_row28_col5\" class=\"data row28 col5\" >0.946186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_29873_row29_col0\" class=\"data row29 col0\" >2</td>\n",
       "      <td id=\"T_29873_row29_col1\" class=\"data row29 col1\" >10</td>\n",
       "      <td id=\"T_29873_row29_col2\" class=\"data row29 col2\" >0.926116</td>\n",
       "      <td id=\"T_29873_row29_col3\" class=\"data row29 col3\" >0.941343</td>\n",
       "      <td id=\"T_29873_row29_col4\" class=\"data row29 col4\" >0.945890</td>\n",
       "      <td id=\"T_29873_row29_col5\" class=\"data row29 col5\" >0.941663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_29873_row30_col0\" class=\"data row30 col0\" >2</td>\n",
       "      <td id=\"T_29873_row30_col1\" class=\"data row30 col1\" >12</td>\n",
       "      <td id=\"T_29873_row30_col2\" class=\"data row30 col2\" >0.922946</td>\n",
       "      <td id=\"T_29873_row30_col3\" class=\"data row30 col3\" >0.939554</td>\n",
       "      <td id=\"T_29873_row30_col4\" class=\"data row30 col4\" >0.943298</td>\n",
       "      <td id=\"T_29873_row30_col5\" class=\"data row30 col5\" >0.939246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_29873_row31_col0\" class=\"data row31 col0\" >2</td>\n",
       "      <td id=\"T_29873_row31_col1\" class=\"data row31 col1\" >14</td>\n",
       "      <td id=\"T_29873_row31_col2\" class=\"data row31 col2\" >0.911409</td>\n",
       "      <td id=\"T_29873_row31_col3\" class=\"data row31 col3\" >0.932334</td>\n",
       "      <td id=\"T_29873_row31_col4\" class=\"data row31 col4\" >0.932930</td>\n",
       "      <td id=\"T_29873_row31_col5\" class=\"data row31 col5\" >0.928875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_29873_row32_col0\" class=\"data row32 col0\" >2</td>\n",
       "      <td id=\"T_29873_row32_col1\" class=\"data row32 col1\" >16</td>\n",
       "      <td id=\"T_29873_row32_col2\" class=\"data row32 col2\" >0.909008</td>\n",
       "      <td id=\"T_29873_row32_col3\" class=\"data row32 col3\" >0.930839</td>\n",
       "      <td id=\"T_29873_row32_col4\" class=\"data row32 col4\" >0.930030</td>\n",
       "      <td id=\"T_29873_row32_col5\" class=\"data row32 col5\" >0.925802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_29873_row33_col0\" class=\"data row33 col0\" >2</td>\n",
       "      <td id=\"T_29873_row33_col1\" class=\"data row33 col1\" >18</td>\n",
       "      <td id=\"T_29873_row33_col2\" class=\"data row33 col2\" >0.907726</td>\n",
       "      <td id=\"T_29873_row33_col3\" class=\"data row33 col3\" >0.929803</td>\n",
       "      <td id=\"T_29873_row33_col4\" class=\"data row33 col4\" >0.929397</td>\n",
       "      <td id=\"T_29873_row33_col5\" class=\"data row33 col5\" >0.925070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_29873_row34_col0\" class=\"data row34 col0\" >2</td>\n",
       "      <td id=\"T_29873_row34_col1\" class=\"data row34 col1\" >20</td>\n",
       "      <td id=\"T_29873_row34_col2\" class=\"data row34 col2\" >0.906141</td>\n",
       "      <td id=\"T_29873_row34_col3\" class=\"data row34 col3\" >0.928989</td>\n",
       "      <td id=\"T_29873_row34_col4\" class=\"data row34 col4\" >0.928168</td>\n",
       "      <td id=\"T_29873_row34_col5\" class=\"data row34 col5\" >0.924181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_29873_row35_col0\" class=\"data row35 col0\" >2</td>\n",
       "      <td id=\"T_29873_row35_col1\" class=\"data row35 col1\" >22</td>\n",
       "      <td id=\"T_29873_row35_col2\" class=\"data row35 col2\" >0.916583</td>\n",
       "      <td id=\"T_29873_row35_col3\" class=\"data row35 col3\" >0.935787</td>\n",
       "      <td id=\"T_29873_row35_col4\" class=\"data row35 col4\" >0.937295</td>\n",
       "      <td id=\"T_29873_row35_col5\" class=\"data row35 col5\" >0.933759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_29873_row36_col0\" class=\"data row36 col0\" >2</td>\n",
       "      <td id=\"T_29873_row36_col1\" class=\"data row36 col1\" >24</td>\n",
       "      <td id=\"T_29873_row36_col2\" class=\"data row36 col2\" >0.902249</td>\n",
       "      <td id=\"T_29873_row36_col3\" class=\"data row36 col3\" >0.927411</td>\n",
       "      <td id=\"T_29873_row36_col4\" class=\"data row36 col4\" >0.924141</td>\n",
       "      <td id=\"T_29873_row36_col5\" class=\"data row36 col5\" >0.920089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_29873_row37_col0\" class=\"data row37 col0\" >2</td>\n",
       "      <td id=\"T_29873_row37_col1\" class=\"data row37 col1\" >26</td>\n",
       "      <td id=\"T_29873_row37_col2\" class=\"data row37 col2\" >0.900058</td>\n",
       "      <td id=\"T_29873_row37_col3\" class=\"data row37 col3\" >0.924541</td>\n",
       "      <td id=\"T_29873_row37_col4\" class=\"data row37 col4\" >0.923013</td>\n",
       "      <td id=\"T_29873_row37_col5\" class=\"data row37 col5\" >0.918571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_29873_row38_col0\" class=\"data row38 col0\" >2</td>\n",
       "      <td id=\"T_29873_row38_col1\" class=\"data row38 col1\" >28</td>\n",
       "      <td id=\"T_29873_row38_col2\" class=\"data row38 col2\" >0.908822</td>\n",
       "      <td id=\"T_29873_row38_col3\" class=\"data row38 col3\" >0.930978</td>\n",
       "      <td id=\"T_29873_row38_col4\" class=\"data row38 col4\" >0.930246</td>\n",
       "      <td id=\"T_29873_row38_col5\" class=\"data row38 col5\" >0.926358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_29873_row39_col0\" class=\"data row39 col0\" >2</td>\n",
       "      <td id=\"T_29873_row39_col1\" class=\"data row39 col1\" >30</td>\n",
       "      <td id=\"T_29873_row39_col2\" class=\"data row39 col2\" >0.905093</td>\n",
       "      <td id=\"T_29873_row39_col3\" class=\"data row39 col3\" >0.928011</td>\n",
       "      <td id=\"T_29873_row39_col4\" class=\"data row39 col4\" >0.926933</td>\n",
       "      <td id=\"T_29873_row39_col5\" class=\"data row39 col5\" >0.922705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_29873_row40_col0\" class=\"data row40 col0\" >2</td>\n",
       "      <td id=\"T_29873_row40_col1\" class=\"data row40 col1\" >32</td>\n",
       "      <td id=\"T_29873_row40_col2\" class=\"data row40 col2\" >0.894488</td>\n",
       "      <td id=\"T_29873_row40_col3\" class=\"data row40 col3\" >0.920304</td>\n",
       "      <td id=\"T_29873_row40_col4\" class=\"data row40 col4\" >0.917247</td>\n",
       "      <td id=\"T_29873_row40_col5\" class=\"data row40 col5\" >0.912763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_29873_row41_col0\" class=\"data row41 col0\" >2</td>\n",
       "      <td id=\"T_29873_row41_col1\" class=\"data row41 col1\" >34</td>\n",
       "      <td id=\"T_29873_row41_col2\" class=\"data row41 col2\" >0.902016</td>\n",
       "      <td id=\"T_29873_row41_col3\" class=\"data row41 col3\" >0.926510</td>\n",
       "      <td id=\"T_29873_row41_col4\" class=\"data row41 col4\" >0.923150</td>\n",
       "      <td id=\"T_29873_row41_col5\" class=\"data row41 col5\" >0.919658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_29873_row42_col0\" class=\"data row42 col0\" >2</td>\n",
       "      <td id=\"T_29873_row42_col1\" class=\"data row42 col1\" >36</td>\n",
       "      <td id=\"T_29873_row42_col2\" class=\"data row42 col2\" >0.904440</td>\n",
       "      <td id=\"T_29873_row42_col3\" class=\"data row42 col3\" >0.927290</td>\n",
       "      <td id=\"T_29873_row42_col4\" class=\"data row42 col4\" >0.926304</td>\n",
       "      <td id=\"T_29873_row42_col5\" class=\"data row42 col5\" >0.922427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_29873_row43_col0\" class=\"data row43 col0\" >2</td>\n",
       "      <td id=\"T_29873_row43_col1\" class=\"data row43 col1\" >38</td>\n",
       "      <td id=\"T_29873_row43_col2\" class=\"data row43 col2\" >0.899499</td>\n",
       "      <td id=\"T_29873_row43_col3\" class=\"data row43 col3\" >0.923991</td>\n",
       "      <td id=\"T_29873_row43_col4\" class=\"data row43 col4\" >0.921565</td>\n",
       "      <td id=\"T_29873_row43_col5\" class=\"data row43 col5\" >0.917474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_29873_row44_col0\" class=\"data row44 col0\" >2</td>\n",
       "      <td id=\"T_29873_row44_col1\" class=\"data row44 col1\" >40</td>\n",
       "      <td id=\"T_29873_row44_col2\" class=\"data row44 col2\" >0.898380</td>\n",
       "      <td id=\"T_29873_row44_col3\" class=\"data row44 col3\" >0.922485</td>\n",
       "      <td id=\"T_29873_row44_col4\" class=\"data row44 col4\" >0.920563</td>\n",
       "      <td id=\"T_29873_row44_col5\" class=\"data row44 col5\" >0.916504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_29873_row45_col0\" class=\"data row45 col0\" >2</td>\n",
       "      <td id=\"T_29873_row45_col1\" class=\"data row45 col1\" >42</td>\n",
       "      <td id=\"T_29873_row45_col2\" class=\"data row45 col2\" >0.892553</td>\n",
       "      <td id=\"T_29873_row45_col3\" class=\"data row45 col3\" >0.919115</td>\n",
       "      <td id=\"T_29873_row45_col4\" class=\"data row45 col4\" >0.915038</td>\n",
       "      <td id=\"T_29873_row45_col5\" class=\"data row45 col5\" >0.910754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_29873_row46_col0\" class=\"data row46 col0\" >2</td>\n",
       "      <td id=\"T_29873_row46_col1\" class=\"data row46 col1\" >44</td>\n",
       "      <td id=\"T_29873_row46_col2\" class=\"data row46 col2\" >0.898170</td>\n",
       "      <td id=\"T_29873_row46_col3\" class=\"data row46 col3\" >0.922523</td>\n",
       "      <td id=\"T_29873_row46_col4\" class=\"data row46 col4\" >0.920388</td>\n",
       "      <td id=\"T_29873_row46_col5\" class=\"data row46 col5\" >0.916397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_29873_row47_col0\" class=\"data row47 col0\" >2</td>\n",
       "      <td id=\"T_29873_row47_col1\" class=\"data row47 col1\" >46</td>\n",
       "      <td id=\"T_29873_row47_col2\" class=\"data row47 col2\" >0.893835</td>\n",
       "      <td id=\"T_29873_row47_col3\" class=\"data row47 col3\" >0.919424</td>\n",
       "      <td id=\"T_29873_row47_col4\" class=\"data row47 col4\" >0.916306</td>\n",
       "      <td id=\"T_29873_row47_col5\" class=\"data row47 col5\" >0.913059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_29873_row48_col0\" class=\"data row48 col0\" >2</td>\n",
       "      <td id=\"T_29873_row48_col1\" class=\"data row48 col1\" >48</td>\n",
       "      <td id=\"T_29873_row48_col2\" class=\"data row48 col2\" >0.899942</td>\n",
       "      <td id=\"T_29873_row48_col3\" class=\"data row48 col3\" >0.924163</td>\n",
       "      <td id=\"T_29873_row48_col4\" class=\"data row48 col4\" >0.921399</td>\n",
       "      <td id=\"T_29873_row48_col5\" class=\"data row48 col5\" >0.917841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_29873_row49_col0\" class=\"data row49 col0\" >2</td>\n",
       "      <td id=\"T_29873_row49_col1\" class=\"data row49 col1\" >50</td>\n",
       "      <td id=\"T_29873_row49_col2\" class=\"data row49 col2\" >0.890689</td>\n",
       "      <td id=\"T_29873_row49_col3\" class=\"data row49 col3\" >0.916685</td>\n",
       "      <td id=\"T_29873_row49_col4\" class=\"data row49 col4\" >0.913370</td>\n",
       "      <td id=\"T_29873_row49_col5\" class=\"data row49 col5\" >0.909058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_29873_row50_col0\" class=\"data row50 col0\" >3</td>\n",
       "      <td id=\"T_29873_row50_col1\" class=\"data row50 col1\" >2</td>\n",
       "      <td id=\"T_29873_row50_col2\" class=\"data row50 col2\" >0.946207</td>\n",
       "      <td id=\"T_29873_row50_col3\" class=\"data row50 col3\" >0.956839</td>\n",
       "      <td id=\"T_29873_row50_col4\" class=\"data row50 col4\" >0.962379</td>\n",
       "      <td id=\"T_29873_row50_col5\" class=\"data row50 col5\" >0.958673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_29873_row51_col0\" class=\"data row51 col0\" >3</td>\n",
       "      <td id=\"T_29873_row51_col1\" class=\"data row51 col1\" >4</td>\n",
       "      <td id=\"T_29873_row51_col2\" class=\"data row51 col2\" >0.936721</td>\n",
       "      <td id=\"T_29873_row51_col3\" class=\"data row51 col3\" >0.948637</td>\n",
       "      <td id=\"T_29873_row51_col4\" class=\"data row51 col4\" >0.953743</td>\n",
       "      <td id=\"T_29873_row51_col5\" class=\"data row51 col5\" >0.950177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_29873_row52_col0\" class=\"data row52 col0\" >3</td>\n",
       "      <td id=\"T_29873_row52_col1\" class=\"data row52 col1\" >6</td>\n",
       "      <td id=\"T_29873_row52_col2\" class=\"data row52 col2\" >0.929379</td>\n",
       "      <td id=\"T_29873_row52_col3\" class=\"data row52 col3\" >0.942276</td>\n",
       "      <td id=\"T_29873_row52_col4\" class=\"data row52 col4\" >0.949078</td>\n",
       "      <td id=\"T_29873_row52_col5\" class=\"data row52 col5\" >0.943856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_29873_row53_col0\" class=\"data row53 col0\" >3</td>\n",
       "      <td id=\"T_29873_row53_col1\" class=\"data row53 col1\" >8</td>\n",
       "      <td id=\"T_29873_row53_col2\" class=\"data row53 col2\" >0.932968</td>\n",
       "      <td id=\"T_29873_row53_col3\" class=\"data row53 col3\" >0.945092</td>\n",
       "      <td id=\"T_29873_row53_col4\" class=\"data row53 col4\" >0.952245</td>\n",
       "      <td id=\"T_29873_row53_col5\" class=\"data row53 col5\" >0.947043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_29873_row54_col0\" class=\"data row54 col0\" >3</td>\n",
       "      <td id=\"T_29873_row54_col1\" class=\"data row54 col1\" >10</td>\n",
       "      <td id=\"T_29873_row54_col2\" class=\"data row54 col2\" >0.934553</td>\n",
       "      <td id=\"T_29873_row54_col3\" class=\"data row54 col3\" >0.946450</td>\n",
       "      <td id=\"T_29873_row54_col4\" class=\"data row54 col4\" >0.954114</td>\n",
       "      <td id=\"T_29873_row54_col5\" class=\"data row54 col5\" >0.948568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_29873_row55_col0\" class=\"data row55 col0\" >3</td>\n",
       "      <td id=\"T_29873_row55_col1\" class=\"data row55 col1\" >12</td>\n",
       "      <td id=\"T_29873_row55_col2\" class=\"data row55 col2\" >0.926162</td>\n",
       "      <td id=\"T_29873_row55_col3\" class=\"data row55 col3\" >0.940480</td>\n",
       "      <td id=\"T_29873_row55_col4\" class=\"data row55 col4\" >0.947312</td>\n",
       "      <td id=\"T_29873_row55_col5\" class=\"data row55 col5\" >0.941718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_29873_row56_col0\" class=\"data row56 col0\" >3</td>\n",
       "      <td id=\"T_29873_row56_col1\" class=\"data row56 col1\" >14</td>\n",
       "      <td id=\"T_29873_row56_col2\" class=\"data row56 col2\" >0.925277</td>\n",
       "      <td id=\"T_29873_row56_col3\" class=\"data row56 col3\" >0.939472</td>\n",
       "      <td id=\"T_29873_row56_col4\" class=\"data row56 col4\" >0.945829</td>\n",
       "      <td id=\"T_29873_row56_col5\" class=\"data row56 col5\" >0.940498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_29873_row57_col0\" class=\"data row57 col0\" >3</td>\n",
       "      <td id=\"T_29873_row57_col1\" class=\"data row57 col1\" >16</td>\n",
       "      <td id=\"T_29873_row57_col2\" class=\"data row57 col2\" >0.929845</td>\n",
       "      <td id=\"T_29873_row57_col3\" class=\"data row57 col3\" >0.943693</td>\n",
       "      <td id=\"T_29873_row57_col4\" class=\"data row57 col4\" >0.949811</td>\n",
       "      <td id=\"T_29873_row57_col5\" class=\"data row57 col5\" >0.944992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_29873_row58_col0\" class=\"data row58 col0\" >3</td>\n",
       "      <td id=\"T_29873_row58_col1\" class=\"data row58 col1\" >18</td>\n",
       "      <td id=\"T_29873_row58_col2\" class=\"data row58 col2\" >0.919753</td>\n",
       "      <td id=\"T_29873_row58_col3\" class=\"data row58 col3\" >0.935072</td>\n",
       "      <td id=\"T_29873_row58_col4\" class=\"data row58 col4\" >0.941321</td>\n",
       "      <td id=\"T_29873_row58_col5\" class=\"data row58 col5\" >0.935686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_29873_row59_col0\" class=\"data row59 col0\" >3</td>\n",
       "      <td id=\"T_29873_row59_col1\" class=\"data row59 col1\" >20</td>\n",
       "      <td id=\"T_29873_row59_col2\" class=\"data row59 col2\" >0.922713</td>\n",
       "      <td id=\"T_29873_row59_col3\" class=\"data row59 col3\" >0.938700</td>\n",
       "      <td id=\"T_29873_row59_col4\" class=\"data row59 col4\" >0.943617</td>\n",
       "      <td id=\"T_29873_row59_col5\" class=\"data row59 col5\" >0.939293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_29873_row60_col0\" class=\"data row60 col0\" >3</td>\n",
       "      <td id=\"T_29873_row60_col1\" class=\"data row60 col1\" >22</td>\n",
       "      <td id=\"T_29873_row60_col2\" class=\"data row60 col2\" >0.909614</td>\n",
       "      <td id=\"T_29873_row60_col3\" class=\"data row60 col3\" >0.928142</td>\n",
       "      <td id=\"T_29873_row60_col4\" class=\"data row60 col4\" >0.931974</td>\n",
       "      <td id=\"T_29873_row60_col5\" class=\"data row60 col5\" >0.926236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_29873_row61_col0\" class=\"data row61 col0\" >3</td>\n",
       "      <td id=\"T_29873_row61_col1\" class=\"data row61 col1\" >24</td>\n",
       "      <td id=\"T_29873_row61_col2\" class=\"data row61 col2\" >0.909521</td>\n",
       "      <td id=\"T_29873_row61_col3\" class=\"data row61 col3\" >0.929242</td>\n",
       "      <td id=\"T_29873_row61_col4\" class=\"data row61 col4\" >0.931116</td>\n",
       "      <td id=\"T_29873_row61_col5\" class=\"data row61 col5\" >0.926970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_29873_row62_col0\" class=\"data row62 col0\" >3</td>\n",
       "      <td id=\"T_29873_row62_col1\" class=\"data row62 col1\" >26</td>\n",
       "      <td id=\"T_29873_row62_col2\" class=\"data row62 col2\" >0.907913</td>\n",
       "      <td id=\"T_29873_row62_col3\" class=\"data row62 col3\" >0.928367</td>\n",
       "      <td id=\"T_29873_row62_col4\" class=\"data row62 col4\" >0.930818</td>\n",
       "      <td id=\"T_29873_row62_col5\" class=\"data row62 col5\" >0.926151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_29873_row63_col0\" class=\"data row63 col0\" >3</td>\n",
       "      <td id=\"T_29873_row63_col1\" class=\"data row63 col1\" >28</td>\n",
       "      <td id=\"T_29873_row63_col2\" class=\"data row63 col2\" >0.899289</td>\n",
       "      <td id=\"T_29873_row63_col3\" class=\"data row63 col3\" >0.922410</td>\n",
       "      <td id=\"T_29873_row63_col4\" class=\"data row63 col4\" >0.922524</td>\n",
       "      <td id=\"T_29873_row63_col5\" class=\"data row63 col5\" >0.917563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_29873_row64_col0\" class=\"data row64 col0\" >3</td>\n",
       "      <td id=\"T_29873_row64_col1\" class=\"data row64 col1\" >30</td>\n",
       "      <td id=\"T_29873_row64_col2\" class=\"data row64 col2\" >0.911362</td>\n",
       "      <td id=\"T_29873_row64_col3\" class=\"data row64 col3\" >0.930519</td>\n",
       "      <td id=\"T_29873_row64_col4\" class=\"data row64 col4\" >0.933387</td>\n",
       "      <td id=\"T_29873_row64_col5\" class=\"data row64 col5\" >0.928670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_29873_row65_col0\" class=\"data row65 col0\" >3</td>\n",
       "      <td id=\"T_29873_row65_col1\" class=\"data row65 col1\" >32</td>\n",
       "      <td id=\"T_29873_row65_col2\" class=\"data row65 col2\" >0.904790</td>\n",
       "      <td id=\"T_29873_row65_col3\" class=\"data row65 col3\" >0.926489</td>\n",
       "      <td id=\"T_29873_row65_col4\" class=\"data row65 col4\" >0.926713</td>\n",
       "      <td id=\"T_29873_row65_col5\" class=\"data row65 col5\" >0.922539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_29873_row66_col0\" class=\"data row66 col0\" >3</td>\n",
       "      <td id=\"T_29873_row66_col1\" class=\"data row66 col1\" >34</td>\n",
       "      <td id=\"T_29873_row66_col2\" class=\"data row66 col2\" >0.893136</td>\n",
       "      <td id=\"T_29873_row66_col3\" class=\"data row66 col3\" >0.917333</td>\n",
       "      <td id=\"T_29873_row66_col4\" class=\"data row66 col4\" >0.917187</td>\n",
       "      <td id=\"T_29873_row66_col5\" class=\"data row66 col5\" >0.911570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_29873_row67_col0\" class=\"data row67 col0\" >3</td>\n",
       "      <td id=\"T_29873_row67_col1\" class=\"data row67 col1\" >36</td>\n",
       "      <td id=\"T_29873_row67_col2\" class=\"data row67 col2\" >0.891807</td>\n",
       "      <td id=\"T_29873_row67_col3\" class=\"data row67 col3\" >0.917831</td>\n",
       "      <td id=\"T_29873_row67_col4\" class=\"data row67 col4\" >0.914676</td>\n",
       "      <td id=\"T_29873_row67_col5\" class=\"data row67 col5\" >0.911751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_29873_row68_col0\" class=\"data row68 col0\" >3</td>\n",
       "      <td id=\"T_29873_row68_col1\" class=\"data row68 col1\" >38</td>\n",
       "      <td id=\"T_29873_row68_col2\" class=\"data row68 col2\" >0.890549</td>\n",
       "      <td id=\"T_29873_row68_col3\" class=\"data row68 col3\" >0.916913</td>\n",
       "      <td id=\"T_29873_row68_col4\" class=\"data row68 col4\" >0.913813</td>\n",
       "      <td id=\"T_29873_row68_col5\" class=\"data row68 col5\" >0.910189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_29873_row69_col0\" class=\"data row69 col0\" >3</td>\n",
       "      <td id=\"T_29873_row69_col1\" class=\"data row69 col1\" >40</td>\n",
       "      <td id=\"T_29873_row69_col2\" class=\"data row69 col2\" >0.905699</td>\n",
       "      <td id=\"T_29873_row69_col3\" class=\"data row69 col3\" >0.926135</td>\n",
       "      <td id=\"T_29873_row69_col4\" class=\"data row69 col4\" >0.927112</td>\n",
       "      <td id=\"T_29873_row69_col5\" class=\"data row69 col5\" >0.922932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_29873_row70_col0\" class=\"data row70 col0\" >3</td>\n",
       "      <td id=\"T_29873_row70_col1\" class=\"data row70 col1\" >42</td>\n",
       "      <td id=\"T_29873_row70_col2\" class=\"data row70 col2\" >0.896702</td>\n",
       "      <td id=\"T_29873_row70_col3\" class=\"data row70 col3\" >0.921262</td>\n",
       "      <td id=\"T_29873_row70_col4\" class=\"data row70 col4\" >0.919030</td>\n",
       "      <td id=\"T_29873_row70_col5\" class=\"data row70 col5\" >0.915119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_29873_row71_col0\" class=\"data row71 col0\" >3</td>\n",
       "      <td id=\"T_29873_row71_col1\" class=\"data row71 col1\" >44</td>\n",
       "      <td id=\"T_29873_row71_col2\" class=\"data row71 col2\" >0.883603</td>\n",
       "      <td id=\"T_29873_row71_col3\" class=\"data row71 col3\" >0.912216</td>\n",
       "      <td id=\"T_29873_row71_col4\" class=\"data row71 col4\" >0.907167</td>\n",
       "      <td id=\"T_29873_row71_col5\" class=\"data row71 col5\" >0.903915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_29873_row72_col0\" class=\"data row72 col0\" >3</td>\n",
       "      <td id=\"T_29873_row72_col1\" class=\"data row72 col1\" >46</td>\n",
       "      <td id=\"T_29873_row72_col2\" class=\"data row72 col2\" >0.894604</td>\n",
       "      <td id=\"T_29873_row72_col3\" class=\"data row72 col3\" >0.920015</td>\n",
       "      <td id=\"T_29873_row72_col4\" class=\"data row72 col4\" >0.917779</td>\n",
       "      <td id=\"T_29873_row72_col5\" class=\"data row72 col5\" >0.913838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_29873_row73_col0\" class=\"data row73 col0\" >3</td>\n",
       "      <td id=\"T_29873_row73_col1\" class=\"data row73 col1\" >48</td>\n",
       "      <td id=\"T_29873_row73_col2\" class=\"data row73 col2\" >0.894301</td>\n",
       "      <td id=\"T_29873_row73_col3\" class=\"data row73 col3\" >0.919304</td>\n",
       "      <td id=\"T_29873_row73_col4\" class=\"data row73 col4\" >0.916933</td>\n",
       "      <td id=\"T_29873_row73_col5\" class=\"data row73 col5\" >0.913151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_29873_row74_col0\" class=\"data row74 col0\" >3</td>\n",
       "      <td id=\"T_29873_row74_col1\" class=\"data row74 col1\" >50</td>\n",
       "      <td id=\"T_29873_row74_col2\" class=\"data row74 col2\" >0.895630</td>\n",
       "      <td id=\"T_29873_row74_col3\" class=\"data row74 col3\" >0.920497</td>\n",
       "      <td id=\"T_29873_row74_col4\" class=\"data row74 col4\" >0.918525</td>\n",
       "      <td id=\"T_29873_row74_col5\" class=\"data row74 col5\" >0.914581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_29873_row75_col0\" class=\"data row75 col0\" >4</td>\n",
       "      <td id=\"T_29873_row75_col1\" class=\"data row75 col1\" >2</td>\n",
       "      <td id=\"T_29873_row75_col2\" class=\"data row75 col2\" >0.951055</td>\n",
       "      <td id=\"T_29873_row75_col3\" class=\"data row75 col3\" >0.960218</td>\n",
       "      <td id=\"T_29873_row75_col4\" class=\"data row75 col4\" >0.965367</td>\n",
       "      <td id=\"T_29873_row75_col5\" class=\"data row75 col5\" >0.962082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_29873_row76_col0\" class=\"data row76 col0\" >4</td>\n",
       "      <td id=\"T_29873_row76_col1\" class=\"data row76 col1\" >4</td>\n",
       "      <td id=\"T_29873_row76_col2\" class=\"data row76 col2\" >0.940636</td>\n",
       "      <td id=\"T_29873_row76_col3\" class=\"data row76 col3\" >0.951398</td>\n",
       "      <td id=\"T_29873_row76_col4\" class=\"data row76 col4\" >0.956972</td>\n",
       "      <td id=\"T_29873_row76_col5\" class=\"data row76 col5\" >0.953144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_29873_row77_col0\" class=\"data row77 col0\" >4</td>\n",
       "      <td id=\"T_29873_row77_col1\" class=\"data row77 col1\" >6</td>\n",
       "      <td id=\"T_29873_row77_col2\" class=\"data row77 col2\" >0.936907</td>\n",
       "      <td id=\"T_29873_row77_col3\" class=\"data row77 col3\" >0.948293</td>\n",
       "      <td id=\"T_29873_row77_col4\" class=\"data row77 col4\" >0.955748</td>\n",
       "      <td id=\"T_29873_row77_col5\" class=\"data row77 col5\" >0.950488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_29873_row78_col0\" class=\"data row78 col0\" >4</td>\n",
       "      <td id=\"T_29873_row78_col1\" class=\"data row78 col1\" >8</td>\n",
       "      <td id=\"T_29873_row78_col2\" class=\"data row78 col2\" >0.930824</td>\n",
       "      <td id=\"T_29873_row78_col3\" class=\"data row78 col3\" >0.943522</td>\n",
       "      <td id=\"T_29873_row78_col4\" class=\"data row78 col4\" >0.950075</td>\n",
       "      <td id=\"T_29873_row78_col5\" class=\"data row78 col5\" >0.945138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_29873_row79_col0\" class=\"data row79 col0\" >4</td>\n",
       "      <td id=\"T_29873_row79_col1\" class=\"data row79 col1\" >10</td>\n",
       "      <td id=\"T_29873_row79_col2\" class=\"data row79 col2\" >0.911386</td>\n",
       "      <td id=\"T_29873_row79_col3\" class=\"data row79 col3\" >0.930487</td>\n",
       "      <td id=\"T_29873_row79_col4\" class=\"data row79 col4\" >0.933075</td>\n",
       "      <td id=\"T_29873_row79_col5\" class=\"data row79 col5\" >0.927923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_29873_row80_col0\" class=\"data row80 col0\" >4</td>\n",
       "      <td id=\"T_29873_row80_col1\" class=\"data row80 col1\" >12</td>\n",
       "      <td id=\"T_29873_row80_col2\" class=\"data row80 col2\" >0.911409</td>\n",
       "      <td id=\"T_29873_row80_col3\" class=\"data row80 col3\" >0.931551</td>\n",
       "      <td id=\"T_29873_row80_col4\" class=\"data row80 col4\" >0.932930</td>\n",
       "      <td id=\"T_29873_row80_col5\" class=\"data row80 col5\" >0.928347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_29873_row81_col0\" class=\"data row81 col0\" >4</td>\n",
       "      <td id=\"T_29873_row81_col1\" class=\"data row81 col1\" >14</td>\n",
       "      <td id=\"T_29873_row81_col2\" class=\"data row81 col2\" >0.911945</td>\n",
       "      <td id=\"T_29873_row81_col3\" class=\"data row81 col3\" >0.930668</td>\n",
       "      <td id=\"T_29873_row81_col4\" class=\"data row81 col4\" >0.933648</td>\n",
       "      <td id=\"T_29873_row81_col5\" class=\"data row81 col5\" >0.928527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_29873_row82_col0\" class=\"data row82 col0\" >4</td>\n",
       "      <td id=\"T_29873_row82_col1\" class=\"data row82 col1\" >16</td>\n",
       "      <td id=\"T_29873_row82_col2\" class=\"data row82 col2\" >0.911549</td>\n",
       "      <td id=\"T_29873_row82_col3\" class=\"data row82 col3\" >0.932199</td>\n",
       "      <td id=\"T_29873_row82_col4\" class=\"data row82 col4\" >0.933169</td>\n",
       "      <td id=\"T_29873_row82_col5\" class=\"data row82 col5\" >0.928759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_29873_row83_col0\" class=\"data row83 col0\" >4</td>\n",
       "      <td id=\"T_29873_row83_col1\" class=\"data row83 col1\" >18</td>\n",
       "      <td id=\"T_29873_row83_col2\" class=\"data row83 col2\" >0.913157</td>\n",
       "      <td id=\"T_29873_row83_col3\" class=\"data row83 col3\" >0.933930</td>\n",
       "      <td id=\"T_29873_row83_col4\" class=\"data row83 col4\" >0.934230</td>\n",
       "      <td id=\"T_29873_row83_col5\" class=\"data row83 col5\" >0.930250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_29873_row84_col0\" class=\"data row84 col0\" >4</td>\n",
       "      <td id=\"T_29873_row84_col1\" class=\"data row84 col1\" >20</td>\n",
       "      <td id=\"T_29873_row84_col2\" class=\"data row84 col2\" >0.913553</td>\n",
       "      <td id=\"T_29873_row84_col3\" class=\"data row84 col3\" >0.934175</td>\n",
       "      <td id=\"T_29873_row84_col4\" class=\"data row84 col4\" >0.934930</td>\n",
       "      <td id=\"T_29873_row84_col5\" class=\"data row84 col5\" >0.930916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_29873_row85_col0\" class=\"data row85 col0\" >4</td>\n",
       "      <td id=\"T_29873_row85_col1\" class=\"data row85 col1\" >22</td>\n",
       "      <td id=\"T_29873_row85_col2\" class=\"data row85 col2\" >0.905535</td>\n",
       "      <td id=\"T_29873_row85_col3\" class=\"data row85 col3\" >0.928636</td>\n",
       "      <td id=\"T_29873_row85_col4\" class=\"data row85 col4\" >0.928116</td>\n",
       "      <td id=\"T_29873_row85_col5\" class=\"data row85 col5\" >0.923707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_29873_row86_col0\" class=\"data row86 col0\" >4</td>\n",
       "      <td id=\"T_29873_row86_col1\" class=\"data row86 col1\" >24</td>\n",
       "      <td id=\"T_29873_row86_col2\" class=\"data row86 col2\" >0.908402</td>\n",
       "      <td id=\"T_29873_row86_col3\" class=\"data row86 col3\" >0.931302</td>\n",
       "      <td id=\"T_29873_row86_col4\" class=\"data row86 col4\" >0.929922</td>\n",
       "      <td id=\"T_29873_row86_col5\" class=\"data row86 col5\" >0.925937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_29873_row87_col0\" class=\"data row87 col0\" >4</td>\n",
       "      <td id=\"T_29873_row87_col1\" class=\"data row87 col1\" >26</td>\n",
       "      <td id=\"T_29873_row87_col2\" class=\"data row87 col2\" >0.906981</td>\n",
       "      <td id=\"T_29873_row87_col3\" class=\"data row87 col3\" >0.930184</td>\n",
       "      <td id=\"T_29873_row87_col4\" class=\"data row87 col4\" >0.928977</td>\n",
       "      <td id=\"T_29873_row87_col5\" class=\"data row87 col5\" >0.924845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_29873_row88_col0\" class=\"data row88 col0\" >4</td>\n",
       "      <td id=\"T_29873_row88_col1\" class=\"data row88 col1\" >28</td>\n",
       "      <td id=\"T_29873_row88_col2\" class=\"data row88 col2\" >0.909638</td>\n",
       "      <td id=\"T_29873_row88_col3\" class=\"data row88 col3\" >0.931712</td>\n",
       "      <td id=\"T_29873_row88_col4\" class=\"data row88 col4\" >0.932334</td>\n",
       "      <td id=\"T_29873_row88_col5\" class=\"data row88 col5\" >0.927979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_29873_row89_col0\" class=\"data row89 col0\" >4</td>\n",
       "      <td id=\"T_29873_row89_col1\" class=\"data row89 col1\" >30</td>\n",
       "      <td id=\"T_29873_row89_col2\" class=\"data row89 col2\" >0.900827</td>\n",
       "      <td id=\"T_29873_row89_col3\" class=\"data row89 col3\" >0.925635</td>\n",
       "      <td id=\"T_29873_row89_col4\" class=\"data row89 col4\" >0.923341</td>\n",
       "      <td id=\"T_29873_row89_col5\" class=\"data row89 col5\" >0.918987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_29873_row90_col0\" class=\"data row90 col0\" >4</td>\n",
       "      <td id=\"T_29873_row90_col1\" class=\"data row90 col1\" >32</td>\n",
       "      <td id=\"T_29873_row90_col2\" class=\"data row90 col2\" >0.904790</td>\n",
       "      <td id=\"T_29873_row90_col3\" class=\"data row90 col3\" >0.928414</td>\n",
       "      <td id=\"T_29873_row90_col4\" class=\"data row90 col4\" >0.928091</td>\n",
       "      <td id=\"T_29873_row90_col5\" class=\"data row90 col5\" >0.923452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_29873_row91_col0\" class=\"data row91 col0\" >4</td>\n",
       "      <td id=\"T_29873_row91_col1\" class=\"data row91 col1\" >34</td>\n",
       "      <td id=\"T_29873_row91_col2\" class=\"data row91 col2\" >0.915301</td>\n",
       "      <td id=\"T_29873_row91_col3\" class=\"data row91 col3\" >0.935704</td>\n",
       "      <td id=\"T_29873_row91_col4\" class=\"data row91 col4\" >0.937072</td>\n",
       "      <td id=\"T_29873_row91_col5\" class=\"data row91 col5\" >0.933073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_29873_row92_col0\" class=\"data row92 col0\" >4</td>\n",
       "      <td id=\"T_29873_row92_col1\" class=\"data row92 col1\" >36</td>\n",
       "      <td id=\"T_29873_row92_col2\" class=\"data row92 col2\" >0.909358</td>\n",
       "      <td id=\"T_29873_row92_col3\" class=\"data row92 col3\" >0.931747</td>\n",
       "      <td id=\"T_29873_row92_col4\" class=\"data row92 col4\" >0.931825</td>\n",
       "      <td id=\"T_29873_row92_col5\" class=\"data row92 col5\" >0.927599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_29873_row93_col0\" class=\"data row93 col0\" >4</td>\n",
       "      <td id=\"T_29873_row93_col1\" class=\"data row93 col1\" >38</td>\n",
       "      <td id=\"T_29873_row93_col2\" class=\"data row93 col2\" >0.903927</td>\n",
       "      <td id=\"T_29873_row93_col3\" class=\"data row93 col3\" >0.927684</td>\n",
       "      <td id=\"T_29873_row93_col4\" class=\"data row93 col4\" >0.926954</td>\n",
       "      <td id=\"T_29873_row93_col5\" class=\"data row93 col5\" >0.922282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_29873_row94_col0\" class=\"data row94 col0\" >4</td>\n",
       "      <td id=\"T_29873_row94_col1\" class=\"data row94 col1\" >40</td>\n",
       "      <td id=\"T_29873_row94_col2\" class=\"data row94 col2\" >0.904766</td>\n",
       "      <td id=\"T_29873_row94_col3\" class=\"data row94 col3\" >0.928396</td>\n",
       "      <td id=\"T_29873_row94_col4\" class=\"data row94 col4\" >0.927012</td>\n",
       "      <td id=\"T_29873_row94_col5\" class=\"data row94 col5\" >0.922911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_29873_row95_col0\" class=\"data row95 col0\" >4</td>\n",
       "      <td id=\"T_29873_row95_col1\" class=\"data row95 col1\" >42</td>\n",
       "      <td id=\"T_29873_row95_col2\" class=\"data row95 col2\" >0.901527</td>\n",
       "      <td id=\"T_29873_row95_col3\" class=\"data row95 col3\" >0.926614</td>\n",
       "      <td id=\"T_29873_row95_col4\" class=\"data row95 col4\" >0.923913</td>\n",
       "      <td id=\"T_29873_row95_col5\" class=\"data row95 col5\" >0.920051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_29873_row96_col0\" class=\"data row96 col0\" >4</td>\n",
       "      <td id=\"T_29873_row96_col1\" class=\"data row96 col1\" >44</td>\n",
       "      <td id=\"T_29873_row96_col2\" class=\"data row96 col2\" >0.907610</td>\n",
       "      <td id=\"T_29873_row96_col3\" class=\"data row96 col3\" >0.929838</td>\n",
       "      <td id=\"T_29873_row96_col4\" class=\"data row96 col4\" >0.928776</td>\n",
       "      <td id=\"T_29873_row96_col5\" class=\"data row96 col5\" >0.925395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_29873_row97_col0\" class=\"data row97 col0\" >4</td>\n",
       "      <td id=\"T_29873_row97_col1\" class=\"data row97 col1\" >46</td>\n",
       "      <td id=\"T_29873_row97_col2\" class=\"data row97 col2\" >0.907050</td>\n",
       "      <td id=\"T_29873_row97_col3\" class=\"data row97 col3\" >0.929250</td>\n",
       "      <td id=\"T_29873_row97_col4\" class=\"data row97 col4\" >0.929116</td>\n",
       "      <td id=\"T_29873_row97_col5\" class=\"data row97 col5\" >0.925952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_29873_row98_col0\" class=\"data row98 col0\" >4</td>\n",
       "      <td id=\"T_29873_row98_col1\" class=\"data row98 col1\" >48</td>\n",
       "      <td id=\"T_29873_row98_col2\" class=\"data row98 col2\" >0.905372</td>\n",
       "      <td id=\"T_29873_row98_col3\" class=\"data row98 col3\" >0.928800</td>\n",
       "      <td id=\"T_29873_row98_col4\" class=\"data row98 col4\" >0.927004</td>\n",
       "      <td id=\"T_29873_row98_col5\" class=\"data row98 col5\" >0.923494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_29873_row99_col0\" class=\"data row99 col0\" >4</td>\n",
       "      <td id=\"T_29873_row99_col1\" class=\"data row99 col1\" >50</td>\n",
       "      <td id=\"T_29873_row99_col2\" class=\"data row99 col2\" >0.906561</td>\n",
       "      <td id=\"T_29873_row99_col3\" class=\"data row99 col3\" >0.929455</td>\n",
       "      <td id=\"T_29873_row99_col4\" class=\"data row99 col4\" >0.927294</td>\n",
       "      <td id=\"T_29873_row99_col5\" class=\"data row99 col5\" >0.924291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
       "      <td id=\"T_29873_row100_col0\" class=\"data row100 col0\" >5</td>\n",
       "      <td id=\"T_29873_row100_col1\" class=\"data row100 col1\" >2</td>\n",
       "      <td id=\"T_29873_row100_col2\" class=\"data row100 col2\" >0.955203</td>\n",
       "      <td id=\"T_29873_row100_col3\" class=\"data row100 col3\" >0.963092</td>\n",
       "      <td id=\"T_29873_row100_col4\" class=\"data row100 col4\" >0.967301</td>\n",
       "      <td id=\"T_29873_row100_col5\" class=\"data row100 col5\" >0.964606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
       "      <td id=\"T_29873_row101_col0\" class=\"data row101 col0\" >5</td>\n",
       "      <td id=\"T_29873_row101_col1\" class=\"data row101 col1\" >4</td>\n",
       "      <td id=\"T_29873_row101_col2\" class=\"data row101 col2\" >0.935066</td>\n",
       "      <td id=\"T_29873_row101_col3\" class=\"data row101 col3\" >0.946830</td>\n",
       "      <td id=\"T_29873_row101_col4\" class=\"data row101 col4\" >0.952913</td>\n",
       "      <td id=\"T_29873_row101_col5\" class=\"data row101 col5\" >0.948572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
       "      <td id=\"T_29873_row102_col0\" class=\"data row102 col0\" >5</td>\n",
       "      <td id=\"T_29873_row102_col1\" class=\"data row102 col1\" >6</td>\n",
       "      <td id=\"T_29873_row102_col2\" class=\"data row102 col2\" >0.930731</td>\n",
       "      <td id=\"T_29873_row102_col3\" class=\"data row102 col3\" >0.944376</td>\n",
       "      <td id=\"T_29873_row102_col4\" class=\"data row102 col4\" >0.949550</td>\n",
       "      <td id=\"T_29873_row102_col5\" class=\"data row102 col5\" >0.945529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
       "      <td id=\"T_29873_row103_col0\" class=\"data row103 col0\" >5</td>\n",
       "      <td id=\"T_29873_row103_col1\" class=\"data row103 col1\" >8</td>\n",
       "      <td id=\"T_29873_row103_col2\" class=\"data row103 col2\" >0.927444</td>\n",
       "      <td id=\"T_29873_row103_col3\" class=\"data row103 col3\" >0.941067</td>\n",
       "      <td id=\"T_29873_row103_col4\" class=\"data row103 col4\" >0.947310</td>\n",
       "      <td id=\"T_29873_row103_col5\" class=\"data row103 col5\" >0.942247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
       "      <td id=\"T_29873_row104_col0\" class=\"data row104 col0\" >5</td>\n",
       "      <td id=\"T_29873_row104_col1\" class=\"data row104 col1\" >10</td>\n",
       "      <td id=\"T_29873_row104_col2\" class=\"data row104 col2\" >0.927934</td>\n",
       "      <td id=\"T_29873_row104_col3\" class=\"data row104 col3\" >0.942802</td>\n",
       "      <td id=\"T_29873_row104_col4\" class=\"data row104 col4\" >0.947855</td>\n",
       "      <td id=\"T_29873_row104_col5\" class=\"data row104 col5\" >0.943416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
       "      <td id=\"T_29873_row105_col0\" class=\"data row105 col0\" >5</td>\n",
       "      <td id=\"T_29873_row105_col1\" class=\"data row105 col1\" >12</td>\n",
       "      <td id=\"T_29873_row105_col2\" class=\"data row105 col2\" >0.913763</td>\n",
       "      <td id=\"T_29873_row105_col3\" class=\"data row105 col3\" >0.931762</td>\n",
       "      <td id=\"T_29873_row105_col4\" class=\"data row105 col4\" >0.935053</td>\n",
       "      <td id=\"T_29873_row105_col5\" class=\"data row105 col5\" >0.929923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
       "      <td id=\"T_29873_row106_col0\" class=\"data row106 col0\" >5</td>\n",
       "      <td id=\"T_29873_row106_col1\" class=\"data row106 col1\" >14</td>\n",
       "      <td id=\"T_29873_row106_col2\" class=\"data row106 col2\" >0.913577</td>\n",
       "      <td id=\"T_29873_row106_col3\" class=\"data row106 col3\" >0.932196</td>\n",
       "      <td id=\"T_29873_row106_col4\" class=\"data row106 col4\" >0.935066</td>\n",
       "      <td id=\"T_29873_row106_col5\" class=\"data row106 col5\" >0.930129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
       "      <td id=\"T_29873_row107_col0\" class=\"data row107 col0\" >5</td>\n",
       "      <td id=\"T_29873_row107_col1\" class=\"data row107 col1\" >16</td>\n",
       "      <td id=\"T_29873_row107_col2\" class=\"data row107 col2\" >0.910267</td>\n",
       "      <td id=\"T_29873_row107_col3\" class=\"data row107 col3\" >0.930585</td>\n",
       "      <td id=\"T_29873_row107_col4\" class=\"data row107 col4\" >0.931906</td>\n",
       "      <td id=\"T_29873_row107_col5\" class=\"data row107 col5\" >0.927151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
       "      <td id=\"T_29873_row108_col0\" class=\"data row108 col0\" >5</td>\n",
       "      <td id=\"T_29873_row108_col1\" class=\"data row108 col1\" >18</td>\n",
       "      <td id=\"T_29873_row108_col2\" class=\"data row108 col2\" >0.911222</td>\n",
       "      <td id=\"T_29873_row108_col3\" class=\"data row108 col3\" >0.931444</td>\n",
       "      <td id=\"T_29873_row108_col4\" class=\"data row108 col4\" >0.933065</td>\n",
       "      <td id=\"T_29873_row108_col5\" class=\"data row108 col5\" >0.928393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
       "      <td id=\"T_29873_row109_col0\" class=\"data row109 col0\" >5</td>\n",
       "      <td id=\"T_29873_row109_col1\" class=\"data row109 col1\" >20</td>\n",
       "      <td id=\"T_29873_row109_col2\" class=\"data row109 col2\" >0.906981</td>\n",
       "      <td id=\"T_29873_row109_col3\" class=\"data row109 col3\" >0.928071</td>\n",
       "      <td id=\"T_29873_row109_col4\" class=\"data row109 col4\" >0.929387</td>\n",
       "      <td id=\"T_29873_row109_col5\" class=\"data row109 col5\" >0.924340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
       "      <td id=\"T_29873_row110_col0\" class=\"data row110 col0\" >5</td>\n",
       "      <td id=\"T_29873_row110_col1\" class=\"data row110 col1\" >22</td>\n",
       "      <td id=\"T_29873_row110_col2\" class=\"data row110 col2\" >0.905232</td>\n",
       "      <td id=\"T_29873_row110_col3\" class=\"data row110 col3\" >0.926957</td>\n",
       "      <td id=\"T_29873_row110_col4\" class=\"data row110 col4\" >0.927783</td>\n",
       "      <td id=\"T_29873_row110_col5\" class=\"data row110 col5\" >0.922701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
       "      <td id=\"T_29873_row111_col0\" class=\"data row111 col0\" >5</td>\n",
       "      <td id=\"T_29873_row111_col1\" class=\"data row111 col1\" >24</td>\n",
       "      <td id=\"T_29873_row111_col2\" class=\"data row111 col2\" >0.911456</td>\n",
       "      <td id=\"T_29873_row111_col3\" class=\"data row111 col3\" >0.930646</td>\n",
       "      <td id=\"T_29873_row111_col4\" class=\"data row111 col4\" >0.932444</td>\n",
       "      <td id=\"T_29873_row111_col5\" class=\"data row111 col5\" >0.927626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
       "      <td id=\"T_29873_row112_col0\" class=\"data row112 col0\" >5</td>\n",
       "      <td id=\"T_29873_row112_col1\" class=\"data row112 col1\" >26</td>\n",
       "      <td id=\"T_29873_row112_col2\" class=\"data row112 col2\" >0.910430</td>\n",
       "      <td id=\"T_29873_row112_col3\" class=\"data row112 col3\" >0.929339</td>\n",
       "      <td id=\"T_29873_row112_col4\" class=\"data row112 col4\" >0.931898</td>\n",
       "      <td id=\"T_29873_row112_col5\" class=\"data row112 col5\" >0.926740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
       "      <td id=\"T_29873_row113_col0\" class=\"data row113 col0\" >5</td>\n",
       "      <td id=\"T_29873_row113_col1\" class=\"data row113 col1\" >28</td>\n",
       "      <td id=\"T_29873_row113_col2\" class=\"data row113 col2\" >0.905885</td>\n",
       "      <td id=\"T_29873_row113_col3\" class=\"data row113 col3\" >0.927072</td>\n",
       "      <td id=\"T_29873_row113_col4\" class=\"data row113 col4\" >0.927711</td>\n",
       "      <td id=\"T_29873_row113_col5\" class=\"data row113 col5\" >0.922910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
       "      <td id=\"T_29873_row114_col0\" class=\"data row114 col0\" >5</td>\n",
       "      <td id=\"T_29873_row114_col1\" class=\"data row114 col1\" >30</td>\n",
       "      <td id=\"T_29873_row114_col2\" class=\"data row114 col2\" >0.908822</td>\n",
       "      <td id=\"T_29873_row114_col3\" class=\"data row114 col3\" >0.928944</td>\n",
       "      <td id=\"T_29873_row114_col4\" class=\"data row114 col4\" >0.930069</td>\n",
       "      <td id=\"T_29873_row114_col5\" class=\"data row114 col5\" >0.925278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
       "      <td id=\"T_29873_row115_col0\" class=\"data row115 col0\" >5</td>\n",
       "      <td id=\"T_29873_row115_col1\" class=\"data row115 col1\" >32</td>\n",
       "      <td id=\"T_29873_row115_col2\" class=\"data row115 col2\" >0.905302</td>\n",
       "      <td id=\"T_29873_row115_col3\" class=\"data row115 col3\" >0.926429</td>\n",
       "      <td id=\"T_29873_row115_col4\" class=\"data row115 col4\" >0.927450</td>\n",
       "      <td id=\"T_29873_row115_col5\" class=\"data row115 col5\" >0.922317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
       "      <td id=\"T_29873_row116_col0\" class=\"data row116 col0\" >5</td>\n",
       "      <td id=\"T_29873_row116_col1\" class=\"data row116 col1\" >34</td>\n",
       "      <td id=\"T_29873_row116_col2\" class=\"data row116 col2\" >0.905489</td>\n",
       "      <td id=\"T_29873_row116_col3\" class=\"data row116 col3\" >0.926199</td>\n",
       "      <td id=\"T_29873_row116_col4\" class=\"data row116 col4\" >0.927602</td>\n",
       "      <td id=\"T_29873_row116_col5\" class=\"data row116 col5\" >0.922321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
       "      <td id=\"T_29873_row117_col0\" class=\"data row117 col0\" >5</td>\n",
       "      <td id=\"T_29873_row117_col1\" class=\"data row117 col1\" >36</td>\n",
       "      <td id=\"T_29873_row117_col2\" class=\"data row117 col2\" >0.903461</td>\n",
       "      <td id=\"T_29873_row117_col3\" class=\"data row117 col3\" >0.925216</td>\n",
       "      <td id=\"T_29873_row117_col4\" class=\"data row117 col4\" >0.925589</td>\n",
       "      <td id=\"T_29873_row117_col5\" class=\"data row117 col5\" >0.920970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
       "      <td id=\"T_29873_row118_col0\" class=\"data row118 col0\" >5</td>\n",
       "      <td id=\"T_29873_row118_col1\" class=\"data row118 col1\" >38</td>\n",
       "      <td id=\"T_29873_row118_col2\" class=\"data row118 col2\" >0.901503</td>\n",
       "      <td id=\"T_29873_row118_col3\" class=\"data row118 col3\" >0.923146</td>\n",
       "      <td id=\"T_29873_row118_col4\" class=\"data row118 col4\" >0.923204</td>\n",
       "      <td id=\"T_29873_row118_col5\" class=\"data row118 col5\" >0.918626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
       "      <td id=\"T_29873_row119_col0\" class=\"data row119 col0\" >5</td>\n",
       "      <td id=\"T_29873_row119_col1\" class=\"data row119 col1\" >40</td>\n",
       "      <td id=\"T_29873_row119_col2\" class=\"data row119 col2\" >0.892810</td>\n",
       "      <td id=\"T_29873_row119_col3\" class=\"data row119 col3\" >0.917539</td>\n",
       "      <td id=\"T_29873_row119_col4\" class=\"data row119 col4\" >0.915296</td>\n",
       "      <td id=\"T_29873_row119_col5\" class=\"data row119 col5\" >0.911824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
       "      <td id=\"T_29873_row120_col0\" class=\"data row120 col0\" >5</td>\n",
       "      <td id=\"T_29873_row120_col1\" class=\"data row120 col1\" >42</td>\n",
       "      <td id=\"T_29873_row120_col2\" class=\"data row120 col2\" >0.914392</td>\n",
       "      <td id=\"T_29873_row120_col3\" class=\"data row120 col3\" >0.931120</td>\n",
       "      <td id=\"T_29873_row120_col4\" class=\"data row120 col4\" >0.935351</td>\n",
       "      <td id=\"T_29873_row120_col5\" class=\"data row120 col5\" >0.930640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
       "      <td id=\"T_29873_row121_col0\" class=\"data row121 col0\" >5</td>\n",
       "      <td id=\"T_29873_row121_col1\" class=\"data row121 col1\" >44</td>\n",
       "      <td id=\"T_29873_row121_col2\" class=\"data row121 col2\" >0.903578</td>\n",
       "      <td id=\"T_29873_row121_col3\" class=\"data row121 col3\" >0.924611</td>\n",
       "      <td id=\"T_29873_row121_col4\" class=\"data row121 col4\" >0.925586</td>\n",
       "      <td id=\"T_29873_row121_col5\" class=\"data row121 col5\" >0.920983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
       "      <td id=\"T_29873_row122_col0\" class=\"data row122 col0\" >5</td>\n",
       "      <td id=\"T_29873_row122_col1\" class=\"data row122 col1\" >46</td>\n",
       "      <td id=\"T_29873_row122_col2\" class=\"data row122 col2\" >0.893066</td>\n",
       "      <td id=\"T_29873_row122_col3\" class=\"data row122 col3\" >0.917960</td>\n",
       "      <td id=\"T_29873_row122_col4\" class=\"data row122 col4\" >0.916266</td>\n",
       "      <td id=\"T_29873_row122_col5\" class=\"data row122 col5\" >0.911028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
       "      <td id=\"T_29873_row123_col0\" class=\"data row123 col0\" >5</td>\n",
       "      <td id=\"T_29873_row123_col1\" class=\"data row123 col1\" >48</td>\n",
       "      <td id=\"T_29873_row123_col2\" class=\"data row123 col2\" >0.898660</td>\n",
       "      <td id=\"T_29873_row123_col3\" class=\"data row123 col3\" >0.921703</td>\n",
       "      <td id=\"T_29873_row123_col4\" class=\"data row123 col4\" >0.921265</td>\n",
       "      <td id=\"T_29873_row123_col5\" class=\"data row123 col5\" >0.916477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29873_level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
       "      <td id=\"T_29873_row124_col0\" class=\"data row124 col0\" >5</td>\n",
       "      <td id=\"T_29873_row124_col1\" class=\"data row124 col1\" >50</td>\n",
       "      <td id=\"T_29873_row124_col2\" class=\"data row124 col2\" >0.894162</td>\n",
       "      <td id=\"T_29873_row124_col3\" class=\"data row124 col3\" >0.917925</td>\n",
       "      <td id=\"T_29873_row124_col4\" class=\"data row124 col4\" >0.917471</td>\n",
       "      <td id=\"T_29873_row124_col5\" class=\"data row124 col5\" >0.912240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24318dbcfa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando qual época teve maior acuracia na validacao para impressao da matriz de confusao\n",
    "resultados_df.style.apply(lambda x: ['background-color: lightblue' if x['acuracia'] > 0.95 else '' for _ in x], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341/1341 [==============================] - 1s 900us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# de acordo com a tabela acima escolha qual modelo você quer imprimir a matriz de confusao\n",
    "fold_escolhido = 4\n",
    "epoch_escolhida = 2\n",
    "modelo_validacao = MLP()\n",
    "modelo_validacao.load_weights(f'modelos salvos/melhor_modelo_fold{fold_escolhido:02d}_epoch{epoch_escolhida:02d}.hdf5')\n",
    "\n",
    "Y_pred = modelo_validacao.predict(X_teste)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "matriz_confusao = confusion_matrix(Y_teste_classes, Y_pred_classes)\n",
    "matriz_confusao_normalizada = matriz_confusao.astype('float') / matriz_confusao.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "POSICAO_labels = dados_validacao['POSICAO'].unique()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Matriz de Confusão', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# se o normalize for False, vai ser as ocorrencias ao inves de %\n",
    "plot_confusion_matrix(matriz_confusao_normalizada, classes=POSICAO_labels, normalize=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>5 - Outros algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_metrics(y_true, y_pred):\n",
    "    acuracia = accuracy_score(y_true, y_pred)\n",
    "    precisao = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return acuracia, precisao, recall, f1\n",
    "\n",
    "resultados = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<font color=green size=6px>5.1 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_dt = {'max_depth': [10, 15, 20, 25, 50], 'min_samples_split': [2, 5, 10, 15, 30]}\n",
    "dt_model = DecisionTreeClassifier()\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5)\n",
    "grid_search_dt.fit(X, Y)\n",
    "melhor_dt_model = grid_search_dt.best_estimator_\n",
    "\n",
    "dt_pred = melhor_dt_model.predict(X_teste)\n",
    "resultados['decision tree'] = compute_multiclass_metrics(Y_teste, dt_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<font color=green size=6px>5.2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid_rf = {'n_estimators': [100, 150], 'max_features': ['sqrt']}\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X, Y)\n",
    "melhor_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "rf_pred = melhor_rf_model.predict(X_teste)\n",
    "resultados['Random Forest'] = compute_multiclass_metrics(Y_teste, rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<font color=green size=6px>5.3 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid_knn = {'n_neighbors': [3, 5]}\n",
    "knn_model = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn_model, param_grid_knn, cv=5)\n",
    "grid_search_knn.fit(X, Y)\n",
    "best_knn_model = grid_search_knn.best_estimator_\n",
    "\n",
    "knn_predictions = best_knn_model.predict(X_teste)\n",
    "resultados['KNN'] = compute_multiclass_metrics(Y_teste, knn_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<font color=green size=6px>5.4 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Y_1d = np.argmax(Y, axis=1) if isinstance(Y, np.ndarray) else Y.idxmax(axis=1)\n",
    "Y_teste_1d = np.argmax(Y_teste, axis=1) if isinstance(Y_teste, np.ndarray) else Y_teste.idxmax(axis=1)\n",
    "\n",
    "param_grid_nb = {'var_smoothing': [1e-9]} \n",
    "nb_model = GaussianNB()\n",
    "grid_search_nb = GridSearchCV(nb_model, param_grid_nb, cv=5)\n",
    "grid_search_nb.fit(X, Y_1d)\n",
    "best_nb_model = grid_search_nb.best_estimator_\n",
    "\n",
    "nb_predictions = best_nb_model.predict(X_teste)\n",
    "resultados['Naive Bayes'] = compute_multiclass_metrics(Y_teste_1d, nb_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<font color=blue size=10px>6 - Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados['MLP'] = resultados_df.loc[75, ['acuracia', 'precisao', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.773406</td>\n",
       "      <td>0.812982</td>\n",
       "      <td>0.817352</td>\n",
       "      <td>0.804392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.837129</td>\n",
       "      <td>0.924140</td>\n",
       "      <td>0.868307</td>\n",
       "      <td>0.885250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.872649</td>\n",
       "      <td>0.893024</td>\n",
       "      <td>0.897466</td>\n",
       "      <td>0.891975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.873861</td>\n",
       "      <td>0.898294</td>\n",
       "      <td>0.895923</td>\n",
       "      <td>0.894308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.951055</td>\n",
       "      <td>0.960218</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.962082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acuracia  precisao    recall  f1-score\n",
       "decision tree  0.773406  0.812982  0.817352  0.804392\n",
       "Random Forest  0.837129  0.924140  0.868307  0.885250\n",
       "KNN            0.872649  0.893024  0.897466  0.891975\n",
       "Naive Bayes    0.873861  0.898294  0.895923  0.894308\n",
       "MLP            0.951055  0.960218  0.965367  0.962082"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_df = pd.DataFrame(resultados, index=['acuracia', 'precisao', 'recall', 'f1-score']).T\n",
    "resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
